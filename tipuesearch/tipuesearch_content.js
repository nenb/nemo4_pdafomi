var tipuesearch = {"pages":[{"title":" NEMO4 PDAFOMI ","text":"NEMO4 PDAFOMI Developer documentation Generating this documentation Developer documentation Insert documentation of the PDAFOMI attachments to the NEMO4 ocean model here. Generating this documentation This documentation is generated by FORD .\nFor more details on the project file and the comment markup in the source code visit the FORD documentation . To regenerate this documentation run: ford docs.md Developer Info Nick Byrne","tags":"home","loc":"index.html"},{"title":"mod_init_pdaf.F90 – NEMO4 PDAFOMI","text":"Contents Modules mod_init_pdaf Source Code mod_init_pdaf.F90 Source Code !>##Initialise PDAF !>This modules contains the initialisation routine for PDAF !>`init_pdaf`. Here the ensemble is initialised and distributed !>and the statevector and state variable information is computed. !> MODULE mod_init_pdaf USE mod_kind_pdaf IMPLICIT NONE SAVE CONTAINS !> This routine collects the initialization of variables for PDAF. !> In addition, the initialization routine `PDAF_init` is called !> such that the internal initialization of PDAF is performed. !> This variant is for the online mode of PDAF. !> !> The ensemble is initialised in `init_ens_pdaf`, and is then !> distributed to the model in `distribute_state_pdaf`. !> !> The statevector dimension, and the offset and dimension of the !> statevector variables is calculated in `calc_statevector_dim`. !> !> Much of the initialisation is read from a PDAF-specific namelist. !> This is performed in `read_config_pdaf`. !> !> **Calling Sequence** !> *Called from:* `nemogcm.F90` !> *Calls:* `calc_statevector_dim` !> *Calls:* `read_config_pdaf` !> *Calls:* `init_pdaf_info` !> *Calls:* `PDAF_init` !> *Calls:* `PDAF_get_state` !> SUBROUTINE init_pdaf () USE mod_parallel_pdaf , & ONLY : n_modeltasks , task_id , COMM_model , COMM_filter , & COMM_couple , mype_ens , filterpe , abort_parallel USE mod_assimilation_pdaf , & ONLY : dim_state_p , screen , filtertype , subtype , dim_ens , & incremental , covartype , type_forget , forget , rank_analysis_enkf , & type_trans , type_sqrt , delt_obs , locweight , local_range , srange USE mod_statevector_pdaf , & ONLY : calc_statevector_dim USE mod_util_pdaf , & ONLY : init_info_pdaf , read_config_pdaf !> Integer parameter array for filter INTEGER :: filter_param_i ( 7 ) !> Real parameter array for filter REAL ( pwp ) :: filter_param_r ( 2 ) !> PDAF status flag INTEGER :: status_pdaf !> Not used in this implementation INTEGER :: doexit , steps !> Not used in this implementation REAL ( pwp ) :: timenow ! Ensemble initialization EXTERNAL :: init_ens_pdaf ! Determine how long until next observation EXTERNAL :: next_observation_pdaf ! Routine to distribute a state vector to model fields EXTERNAL :: distribute_state_pdaf ! User supplied pre/poststep routine EXTERNAL :: prepoststep_ens_pdaf ! *************************** ! ***   Initialize PDAF   *** ! *************************** IF ( mype_ens == 0 ) THEN WRITE ( * , '(/1x,a)' ) 'INITIALIZE PDAF - ONLINE MODE' END IF ! Compute dimension of local statevector. Also compute offset ! and dimension of local state variables CALL calc_statevector_dim ( dim_state_p ) ! ********************************************************** ! ***   CONTROL OF PDAF - used in call to PDAF_init      *** ! ********************************************************** ! *** IO options *** screen = 2 ! Write screen output (1) for output, (2) add timings ! *** Filter specific variables filtertype = 5 ! Type of filter !   (1) SEIK !   (2) EnKF !   (3) LSEIK !   (4) ETKF !   (5) LETKF !   (6) ESTKF !   (7) LESTKF dim_ens = n_modeltasks ! Size of ensemble for all ensemble filters !   We use n_modeltasks here, initialized in init_parallel_pdaf subtype = 0 ! subtype of filter: !   ESTKF: !     (0) Standard form of ESTKF !   LESTKF: !     (0) Standard form of LESTKF type_trans = 0 ! Type of ensemble transformation !   SEIK/LSEIK and ESTKF/LESTKF: !     (0) use deterministic omega !     (1) use random orthonormal omega orthogonal to (1,...,1)&#94;T !     (2) use product of (0) with random orthonormal matrix with !         eigenvector (1,...,1)&#94;T !   ETKF/LETKF: !     (0) use deterministic symmetric transformation !     (2) use product of (0) with random orthonormal matrix with !         eigenvector (1,...,1)&#94;T type_forget = 0 ! Type of forgetting factor in SEIK/LSEIK/ETKF/LETKF/ESTKF/LESTKF !   (0) fixed !   (1) global adaptive !   (2) local adaptive for LSEIK/LETKF/LESTKF forget = 1.0 ! Forgetting factor type_sqrt = 0 ! Type of transform matrix square-root !   (0) symmetric square root, (1) Cholesky decomposition incremental = 0 ! (1) to perform incremental updating (only in SEIK/LSEIK!) covartype = 1 ! Definition of factor in covar. matrix used in SEIK !   (0) for dim_ens&#94;-1 (old SEIK) !   (1) for (dim_ens-1)&#94;-1 (real ensemble covariance matrix) !   This parameter has also to be set internally in PDAF_init. rank_analysis_enkf = 0 ! rank to be considered for inversion of HPH ! in analysis of EnKF; (0) for analysis w/o eigendecomposition ! ********************************************************************* ! ***   Settings for analysis steps  - used in call-back routines   *** ! ********************************************************************* ! *** Forecast length (time interval between analysis steps) *** delt_obs = 24 ! Number of time steps between analysis/assimilation steps ! *** Localization settings locweight = 0 ! Type of localizating weighting !   (0) constant weight of 1 !   (1) exponentially decreasing with SRANGE !   (2) use 5th-order polynomial !   (3) regulated localization of R with mean error variance !   (4) regulated localization of R with single-point error variance local_range = 0 ! Range in grid points for observation domain in local filters srange = local_range ! Support range for 5th-order polynomial ! or range for 1/e for exponential weighting ! ************************** ! Namelist and screen output ! ************************** ! Read namelist file for PDAF CALL read_config_pdaf () ! Screen output for PDAF parameters IF ( mype_ens == 0 ) CALL init_info_pdaf () ! ***************************************************** ! *** Call PDAF initialization routine on all PEs.  *** ! ***                                               *** ! *** Here, the full selection of filters is        *** ! *** implemented. In a real implementation, one    *** ! *** reduce this to selected filters.              *** ! ***                                               *** ! *** For all filters, first the arrays of integer  *** ! *** and real number parameters are initialized.   *** ! *** Subsequently, PDAF_init is called.            *** ! ***************************************************** whichinit : IF ( filtertype == 2 ) THEN ! *** EnKF with Monte Carlo init *** filter_param_i ( 1 ) = dim_state_p ! State dimension filter_param_i ( 2 ) = dim_ens ! Size of ensemble filter_param_i ( 3 ) = rank_analysis_enkf ! Rank of speudo-inverse in analysis filter_param_i ( 4 ) = incremental ! Whether to perform incremental analysis filter_param_i ( 5 ) = 0 ! Smoother lag (not implemented here) filter_param_r ( 1 ) = forget ! Forgetting factor CALL PDAF_init ( filtertype , subtype , 0 , & filter_param_i , 6 , & filter_param_r , 2 , & COMM_model , COMM_filter , COMM_couple , & task_id , n_modeltasks , filterpe , init_ens_pdaf , & screen , status_pdaf ) ELSE ! *** All other filters                       *** ! *** SEIK, LSEIK, ETKF, LETKF, ESTKF, LESTKF *** filter_param_i ( 1 ) = dim_state_p ! State dimension filter_param_i ( 2 ) = dim_ens ! Size of ensemble filter_param_i ( 3 ) = 0 ! Smoother lag (not implemented here) filter_param_i ( 4 ) = incremental ! Whether to perform incremental analysis filter_param_i ( 5 ) = type_forget ! Type of forgetting factor filter_param_i ( 6 ) = type_trans ! Type of ensemble transformation filter_param_i ( 7 ) = type_sqrt ! Type of transform square-root (SEIK-sub4/ESTKF) filter_param_r ( 1 ) = forget ! Forgetting factor CALL PDAF_init ( filtertype , subtype , 0 , & filter_param_i , 7 , & filter_param_r , 2 , & COMM_model , COMM_filter , COMM_couple , & task_id , n_modeltasks , filterpe , init_ens_pdaf , & screen , status_pdaf ) END IF whichinit ! *** Check whether initialization of PDAF was successful *** IF ( status_pdaf /= 0 ) THEN WRITE ( * , '(/1x,a6,i3,a43,i4,a1/)' ) & 'ERROR ' , status_pdaf , & ' in initialization of PDAF - stopping! (PE ' , mype_ens , ')' CALL abort_parallel () END IF ! ********************************** ! *** Prepare ensemble forecasts *** ! ********************************** CALL PDAF_get_state ( steps , timenow , doexit , next_observation_pdaf , & distribute_state_pdaf , prepoststep_ens_pdaf , status_pdaf ) END SUBROUTINE init_pdaf END MODULE mod_init_pdaf","tags":"","loc":"sourcefile/mod_init_pdaf.f90.html"},{"title":"mod_parallel_pdaf.F90 – NEMO4 PDAFOMI","text":"Contents Modules mod_parallel_pdaf Source Code mod_parallel_pdaf.F90 Source Code !>##Setup parallelisation !>This modules provides variables for the MPI parallelization !>to be shared between model-related routines. There are variables !>that are used in the model even without PDAF, and additional variables !>that are only used if data assimilaion with PDAF is performed. !>The initialization of communicators for execution with PDAF is !>performed in `init_parallel_pdaf`. !> MODULE mod_parallel_pdaf USE mod_kind_pdaf IMPLICIT NONE SAVE INCLUDE 'mpif.h' !> MPI communicator for model tasks INTEGER :: COMM_model !> Rank and size in COMM_model INTEGER :: mype_model , npes_model !> Communicator for entire ensemble INTEGER :: COMM_ensemble !> Rank and size in COMM_ensemble INTEGER :: mype_ens , npes_ens !> Number of parallel model tasks INTEGER :: n_modeltasks = 1 !> MPI communicator for filter PEs INTEGER :: COMM_filter !> rank and size in COMM_filter INTEGER :: mype_filter , npes_filter !> MPI communicator for coupling filter and model INTEGER :: COMM_couple !> rank and size in COMM_couple INTEGER :: mype_couple , npes_couple !> Whether we are on a PE in a COMM_filter LOGICAL :: filterpe !> Index of my model task (1,...,n_modeltasks) INTEGER :: task_id !> Error flag for MPI INTEGER :: MPIerr !> Status array for MPI INTEGER :: MPIstatus ( MPI_STATUS_SIZE ) !> Option for screen output INTEGER :: screen_parallel = 1 !> # PEs per ensemble INTEGER , ALLOCATABLE :: local_npes_model (:) CONTAINS !> Terminate the MPI execution environment. SUBROUTINE abort_parallel () CALL MPI_Abort ( MPI_COMM_WORLD , 1 , MPIerr ) END SUBROUTINE abort_parallel !> Split the MPI communicator initialised by XIOS into MODEL, !> FILTER and COUPLE communicators, return MODEL communicator. !> !> **Calling Sequence** !> *Called from:* `lib_mpp.F90` !> *Calls:* `MPI_Comm_size` !> *Calls:* `MPI_Comm_rank` !> *Calls:* `MPI_Comm_split` !> *Calls:* `MPI_Barrier` !> SUBROUTINE init_parallel_pdaf ( screen , mpi_comm ) !> Whether screen information is shown INTEGER , INTENT ( in ) :: screen !> Communicator after XIOS splitting INTEGER , INTENT ( inout ) :: mpi_comm !> Counters INTEGER :: i , j !> Index of PE INTEGER :: pe_index !> Variables for communicator-splitting INTEGER :: my_color , color_couple !> Number of model tasks INTEGER :: tasks !> namelist file CHARACTER ( lc ) :: nmlfile ! Number of ensemble members, supplied by PDAF namelist NAMELIST / tasks_nml / tasks ! Read namelist for number of model tasks nmlfile = 'namelist.pdaf' OPEN ( 20 , file = nmlfile ) READ ( 20 , NML = tasks_nml ) CLOSE ( 20 ) n_modeltasks = tasks ! ***              COMM_ENSEMBLE                *** ! *** Generate communicator for ensemble runs   *** ! *** only used to generate model communicators *** COMM_ensemble = mpi_comm CALL MPI_Comm_Size ( COMM_ensemble , npes_ens , MPIerr ) CALL MPI_Comm_Rank ( COMM_ensemble , mype_ens , MPIerr ) ! Initialize communicators for ensemble evaluations IF ( mype_ens == 0 ) THEN WRITE ( * , '(/1x, a)' ) 'Initialize communicators for assimilation with PDAF' END IF ! Store # PEs per ensemble member. Used for info on PE 0 and for ! generation of model communicators on other PEs ALLOCATE ( local_npes_model ( n_modeltasks )) local_npes_model = FLOOR ( REAL ( npes_ens ) / REAL ( n_modeltasks )) DO i = 1 , ( npes_ens - n_modeltasks * local_npes_model ( 1 )) local_npes_model ( i ) = local_npes_model ( i ) + 1 END DO ! ***              COMM_MODEL               *** ! *** Generate communicators for model runs *** pe_index = 0 doens1 : DO i = 1 , n_modeltasks DO j = 1 , local_npes_model ( i ) IF ( mype_ens == pe_index ) THEN task_id = i EXIT doens1 END IF pe_index = pe_index + 1 END DO END DO doens1 CALL MPI_Comm_split ( COMM_ensemble , task_id , mype_ens , & COMM_model , MPIerr ) ! Re-initialize PE information according to model communicator CALL MPI_Comm_Size ( COMM_model , npes_model , MPIerr ) CALL MPI_Comm_Rank ( COMM_model , mype_model , MPIerr ) IF ( screen > 1 ) then WRITE ( * , * ) 'MODEL: mype(w)= ' , mype_ens , '; model task: ' , task_id , & '; mype(m)= ' , mype_model , '; npes(m)= ' , npes_model END IF ! Init flag FILTERPE (all PEs of model task 1) IF ( task_id == 1 ) THEN filterpe = . TRUE . ELSE filterpe = . FALSE . END IF ! ***         COMM_FILTER                 *** ! *** Generate communicator for filter    *** IF ( filterpe ) THEN my_color = task_id ELSE my_color = MPI_UNDEFINED END IF CALL MPI_Comm_split ( COMM_ensemble , my_color , mype_ens , & COMM_filter , MPIerr ) ! Initialize PE information according to filter communicator IF ( filterpe ) THEN CALL MPI_Comm_Size ( COMM_filter , npes_filter , MPIerr ) CALL MPI_Comm_Rank ( COMM_filter , mype_filter , MPIerr ) END IF ! ***              COMM_COUPLE                 *** ! *** Generate communicators for communication *** ! *** between model and filter PEs             *** color_couple = mype_model + 1 CALL MPI_Comm_split ( COMM_ensemble , color_couple , mype_ens , & COMM_couple , MPIerr ) ! Initialize PE information according to coupling communicator CALL MPI_Comm_Size ( COMM_couple , npes_couple , MPIerr ) CALL MPI_Comm_Rank ( COMM_couple , mype_couple , MPIerr ) IF ( screen > 0 ) THEN IF ( mype_ens == 0 ) THEN WRITE ( * , '(/18x, a)' ) 'PE configuration:' WRITE ( * , '(2x, a6, a9, a10, a14, a13, /2x, a5, a9, a7, a7, a7, a7, a7, /2x, a)' ) & 'world' , 'filter' , 'model' , 'couple' , 'filterPE' , & 'rank' , 'rank' , 'task' , 'rank' , 'task' , 'rank' , 'T/F' , & '----------------------------------------------------------' END IF CALL MPI_Barrier ( COMM_ensemble , MPIerr ) IF ( task_id == 1 ) THEN WRITE ( * , '(2x, i4, 4x, i4, 4x, i3, 4x, i3, 4x, i3, 4x, i3, 5x, l3)' ) & mype_ens , mype_filter , task_id , mype_model , color_couple , & mype_couple , filterpe END IF IF ( task_id > 1 ) THEN WRITE ( * , '(2x, i4, 12x, i3, 4x, i3, 4x, i3, 4x, i3, 5x, l3)' ) & mype_ens , task_id , mype_model , color_couple , mype_couple , filterpe END IF CALL MPI_Barrier ( COMM_ensemble , MPIerr ) IF ( mype_ens == 0 ) WRITE ( * , '(/a)' ) '' END IF ! **************************************************** ! *** Re-initialize model equivalent to COMM_model *** ! **************************************************** mpi_comm = COMM_model END SUBROUTINE init_parallel_pdaf END MODULE mod_parallel_pdaf","tags":"","loc":"sourcefile/mod_parallel_pdaf.f90.html"},{"title":"mod_statevector_pdaf.F90 – NEMO4 PDAFOMI","text":"Contents Modules mod_statevector_pdaf Source Code mod_statevector_pdaf.F90 Source Code !>##Building the Statevector !>This module provides variables & routines for !>building the state vector. !> MODULE mod_statevector_pdaf USE mod_kind_pdaf IMPLICIT NONE SAVE !> 2d statevector variables - start index INTEGER :: ssh_p_offset !> 2d statevector variables - dimension size INTEGER :: ssh_p_dim !> 3d statevector variables - start index INTEGER :: t_p_offset INTEGER :: s_p_offset INTEGER :: u_p_offset INTEGER :: v_p_offset !> 3d statevector variables - dimension size INTEGER :: t_p_dim INTEGER :: s_p_dim INTEGER :: u_p_dim INTEGER :: v_p_dim !> Dimensions for MPI subdomain that is included !> in local statevector. Necessary so that halo !> regions are not included in multiple local !> statevectors INTEGER :: mpi_subd_lat INTEGER :: mpi_subd_lon INTEGER :: mpi_subd_vert CONTAINS !> This routine calculates the dimensions of the MPI subdomain !> that is used to fill the local statevector. SUBROUTINE calc_mpi_dim () USE par_oce , ONLY : jpk USE dom_oce , ONLY : nldi , nldj , nlei , nlej mpi_subd_lon = nlei - nldi + 1 mpi_subd_lat = nlej - nldj + 1 mpi_subd_vert = jpk END SUBROUTINE calc_mpi_dim !> This routine calculates the dimension of each of the local !> statevector variables. SUBROUTINE calc_statevar_dim () ! Compute MPI subdomain dimensions in case not already done CALL calc_mpi_dim () ssh_p_dim = mpi_subd_lat * mpi_subd_lon t_p_dim = mpi_subd_lat * mpi_subd_lon * mpi_subd_vert s_p_dim = mpi_subd_lat * mpi_subd_lon * mpi_subd_vert u_p_dim = mpi_subd_lat * mpi_subd_lon * mpi_subd_vert v_p_dim = mpi_subd_lat * mpi_subd_lon * mpi_subd_vert END SUBROUTINE calc_statevar_dim !> This routine calculates the offset values for each of the !> local statevector variables. It then stores the 2d/3d offset !> values in separate arrays. SUBROUTINE calc_offset () ! Compute local statevector dimensions in case not already done CALL calc_statevar_dim () ssh_p_offset = 0 t_p_offset = ssh_p_offset + ssh_p_dim s_p_offset = t_p_offset + t_p_dim u_p_offset = s_p_offset + s_p_dim v_p_offset = u_p_offset + u_p_dim END SUBROUTINE calc_offset !> This routine calculates the dimension of the local statevector. SUBROUTINE calc_statevector_dim ( dim_p ) !> Local statevector dimension INTEGER , INTENT ( inout ) :: dim_p ! Calculate state variable dimensions in case not already done CALL calc_statevar_dim () dim_p = ssh_p_dim + t_p_dim + s_p_dim + u_p_dim + v_p_dim END SUBROUTINE calc_statevector_dim !> Fill local ensemble array with 2d state variables from !> initial state file. SUBROUTINE fill2d_ensarray ( fname , ens_p ) USE netcdf !> Name of netCDF file CHARACTER ( lc ), INTENT ( in ) :: fname !> PE-local state ensemble REAL ( pwp ), INTENT ( inout ) :: ens_p (:, :) WRITE ( * , '(/1x,a,a)' ) '2D initial state file =' , TRIM ( fname ) WRITE ( * , '(/1x,a)' ) 'Insert routine for reading 2D initial state here.' END SUBROUTINE fill2d_ensarray !> Fill local ensemble array with 3d state variables from !> initial state file. SUBROUTINE fill3d_ensarray ( fname , statevar , ens_p ) USE netcdf !> Name of netCDF file CHARACTER ( lc ), INTENT ( in ) :: fname !> Name of state variable CHARACTER ( len = 1 ), INTENT ( in ) :: statevar !> PE-local state ensemble REAL ( pwp ), INTENT ( inout ) :: ens_p (:, :) SELECT CASE ( statevar ) CASE ( 'T' ) WRITE ( * , '(/1x,a,a)' ) 'T initial state file =' , TRIM ( fname ) WRITE ( * , '(/1x,a)' ) 'Insert routine for reading T initial state here.' CASE ( 'S' ) WRITE ( * , '(/1x,a,a)' ) 'S initial state file =' , TRIM ( fname ) WRITE ( * , '(/1x,a)' ) 'Insert routine for reading S initial state here.' CASE ( 'U' ) WRITE ( * , '(/1x,a,a)' ) 'U initial state file =' , TRIM ( fname ) WRITE ( * , '(/1x,a)' ) 'Insert routine for reading U initial state here.' CASE ( 'V' ) WRITE ( * , '(/1x,a,a)' ) 'V initial state file =' , TRIM ( fname ) WRITE ( * , '(/1x,a)' ) 'Insert routine for reading V initial state here.' END SELECT END SUBROUTINE fill3d_ensarray END MODULE mod_statevector_pdaf","tags":"","loc":"sourcefile/mod_statevector_pdaf.f90.html"},{"title":"distribute_state_pdaf.F90 – NEMO4 PDAFOMI","text":"Contents Subroutines distribute_state_pdaf Source Code distribute_state_pdaf.F90 Source Code !>##Distributing the statevector variables !>The routine has to initialize the fields of the !>model from the statevector of PDAF. !> !>The routine is executed by each process that is !>participating in the model integrations. !> !>**Calling Sequence** !>*Called from:* `PDAF_get_state` (as U_dist_state) !>*Called from:* `PDAF_assimilate_X` (as U_coll_state) !> SUBROUTINE distribute_state_pdaf ( dim_p , state_p ) USE mod_kind_pdaf USE mod_statevector_pdaf , & ONLY : mpi_subd_lat , mpi_subd_lon , mpi_subd_vert , ssh_p_offset , & t_p_offset , s_p_offset , u_p_offset , v_p_offset USE dom_oce , & ONLY : nldj , nldi USE oce , & ONLY : sshb , tsb , ub , vb USE par_oce , & ONLY : jp_tem , jp_sal , jpi , jpj , jpk USE lbclnk , & ONLY : lbc_lnk , lbc_lnk_multi IMPLICIT NONE !> PE-local state dimension INTEGER , INTENT ( in ) :: dim_p !> PE-local state vector REAL ( pwp ), INTENT ( inout ) :: state_p ( dim_p ) !> Counters INTEGER :: i , j , k !> Start index for MPI subdomain INTEGER :: i0 , j0 ! Set the starting index after the halo region j0 = nldj - 1 i0 = nldi - 1 ! ************************************ ! Distribute state vector 2d variables ! ************************************ ! SSH DO j = 1 , mpi_subd_lat DO i = 1 , mpi_subd_lon sshb ( i + i0 , j + j0 ) = state_p ( i + ( j - 1 ) * mpi_subd_lon & + ssh_p_offset ) END DO END DO ! Fill halo regions CALL lbc_lnk ( 'distribute_state_pdaf' , sshb , 'T' , 1. ) ! ************************************ ! Distribute state vector 3d variables ! ************************************ ! T DO k = 1 , mpi_subd_vert DO j = 1 , mpi_subd_lat DO i = 1 , mpi_subd_lon tsb ( i + i0 , j + j0 , k , jp_tem ) = state_p ( i + ( j - 1 ) * mpi_subd_lon & + ( k - 1 ) * mpi_subd_lat * mpi_subd_lon + t_p_offset ) END DO END DO END DO ! S DO k = 1 , mpi_subd_vert DO j = 1 , mpi_subd_lat DO i = 1 , mpi_subd_lon tsb ( i + i0 , j + j0 , k , jp_sal ) = state_p ( i + ( j - 1 ) * mpi_subd_lon & + ( k - 1 ) * mpi_subd_lat * mpi_subd_lon + s_p_offset ) END DO END DO END DO ! Fill halo regions CALL lbc_lnk_multi ( 'distribute_state_pdaf' , tsb (:, :, :, jp_tem ), 'T' , & 1. , tsb (:, :, :, jp_sal ), 'T' , 1. ) ! U DO k = 1 , mpi_subd_vert DO j = 1 , mpi_subd_lat DO i = 1 , mpi_subd_lon ub ( i + i0 , j + j0 , k ) = state_p ( i + ( j - 1 ) * mpi_subd_lon + & ( k - 1 ) * mpi_subd_lat * mpi_subd_lon + u_p_offset ) END DO END DO END DO ! V DO k = 1 , mpi_subd_vert DO j = 1 , mpi_subd_lat DO i = 1 , mpi_subd_lon vb ( i + i0 , j + j0 , k ) = state_p ( i + ( j - 1 ) * mpi_subd_lon + & ( k - 1 ) * mpi_subd_lat * mpi_subd_lon + v_p_offset ) END DO END DO END DO ! Fill halo regions CALL lbc_lnk_multi ( 'distribute_state_pdaf' , ub , 'U' , - 1. , vb , 'V' , - 1. ) END SUBROUTINE distribute_state_pdaf","tags":"","loc":"sourcefile/distribute_state_pdaf.f90.html"},{"title":"mod_util_pdaf.F90 – NEMO4 PDAFOMI","text":"Contents Modules mod_util_pdaf Source Code mod_util_pdaf.F90 Source Code !>##Utility Routines !>This module contains several routines useful for common !>model tasks. The initial routines included output configuration !>information about the PDAF library, and configuration information !>about the assimilation parameters. !> MODULE mod_util_pdaf USE mod_kind_pdaf IMPLICIT NONE SAVE CONTAINS !> This routine performs a model-sided screen output about !> the coniguration of the data assimilation system. !> !> **Calling Sequence** !> *Called from:* `init_pdaf` SUBROUTINE init_info_pdaf () USE mod_assimilation_pdaf , & ! Variables for assimilation ONLY : filtertype , subtype , dim_ens , delt_obs , model_error , & model_err_amp , forget , rank_analysis_enkf , int_rediag ! ***************************** ! *** Initial Screen output *** ! ***************************** IF ( filtertype == 0 ) THEN WRITE ( * , '(/21x, a)' ) 'Filter: SEEK' IF ( subtype == 2 ) THEN WRITE ( * , '(6x, a)' ) '-- fixed basis filter with update of matrix U' WRITE ( * , '(6x, a)' ) '-- no re-diagonalization of VUV&#94;T' ELSE IF ( subtype == 3 ) THEN WRITE ( * , '(6x, a)' ) '-- fixed basis filter & no update of matrix U' WRITE ( * , '(6x, a)' ) '-- no re-diagonalization of VUV&#94;T' ELSE IF ( subtype == 5 ) THEN WRITE ( * , '(6x, a)' ) '-- Offline mode' END IF WRITE ( * , '(13x, a, i5)' ) 'number of EOFs:' , dim_ens IF ( subtype /= 5 ) WRITE ( * , '(6x, a, i5)' ) 'Assimilation interval:' , delt_obs WRITE ( * , '(10x, a, f5.2)' ) 'forgetting factor:' , forget IF ( subtype /= 5 ) THEN IF (( int_rediag > 0 ) . AND . (( subtype /= 2 ) . OR . ( subtype /= 3 ))) & WRITE ( * , '(10x, a, i4, a)' ) & 'Re-diag each ' , int_rediag , '-th analysis step' ELSE IF ( int_rediag == 1 ) THEN WRITE ( * , '(10x, a)' ) 'Perform re-diagonalization' ELSE WRITE ( * , '(10x, a)' ) 'No re-diagonalization' END IF END IF ELSE IF ( filtertype == 1 ) THEN WRITE ( * , '(21x, a)' ) 'Filter: SEIK' IF ( subtype == 2 ) THEN WRITE ( * , '(6x, a)' ) '-- fixed error-space basis' ELSE IF ( subtype == 3 ) THEN WRITE ( * , '(6x, a)' ) '-- fixed state covariance matrix' ELSE IF ( subtype == 4 ) THEN WRITE ( * , '(6x, a)' ) '-- use ensemble transformation' ELSE IF ( subtype == 5 ) THEN WRITE ( * , '(6x, a)' ) '-- Offline mode' END IF WRITE ( * , '(14x, a, i5)' ) 'ensemble size:' , dim_ens IF ( subtype /= 5 ) WRITE ( * , '(6x, a, i5)' ) 'Assimilation interval:' , delt_obs WRITE ( * , '(10x, a, f5.2)' ) 'forgetting factor:' , forget IF ( model_error ) THEN WRITE ( * , '(6x, a, f5.2)' ) 'model error amplitude:' , model_err_amp END IF ELSE IF ( filtertype == 2 ) THEN WRITE ( * , '(21x, a)' ) 'Filter: EnKF' IF ( subtype == 5 ) THEN WRITE ( * , '(6x, a)' ) '-- Offline mode' END IF WRITE ( * , '(14x, a, i5)' ) 'ensemble size:' , dim_ens IF ( subtype /= 5 ) WRITE ( * , '(6x, a, i5)' ) 'Assimilation interval:' , delt_obs WRITE ( * , '(10x, a, f5.2)' ) 'forgetting factor:' , forget IF ( model_error ) THEN WRITE ( * , '(6x, a, f5.2)' ) 'model error amplitude:' , model_err_amp END IF IF ( rank_analysis_enkf > 0 ) THEN WRITE ( * , '(6x, a, i5)' ) & 'analysis with pseudo-inverse of HPH, rank:' , rank_analysis_enkf END IF ELSE IF ( filtertype == 3 ) THEN WRITE ( * , '(21x, a)' ) 'Filter: LSEIK' IF ( subtype == 2 ) THEN WRITE ( * , '(6x, a)' ) '-- fixed error-space basis' ELSE IF ( subtype == 3 ) THEN WRITE ( * , '(6x, a)' ) '-- fixed state covariance matrix' ELSE IF ( subtype == 4 ) THEN WRITE ( * , '(6x, a)' ) '-- use ensemble transformation' ELSE IF ( subtype == 5 ) THEN WRITE ( * , '(6x, a)' ) '-- Offline mode' END IF WRITE ( * , '(14x, a, i5)' ) 'ensemble size:' , dim_ens IF ( subtype /= 5 ) WRITE ( * , '(6x, a, i5)' ) 'Assimilation interval:' , delt_obs WRITE ( * , '(10x, a, f5.2)' ) 'forgetting factor:' , forget IF ( model_error ) THEN WRITE ( * , '(6x, a, f5.2)' ) 'model error amplitude:' , model_err_amp END IF ELSE IF ( filtertype == 4 ) THEN WRITE ( * , '(21x, a)' ) 'Filter: ETKF' IF ( subtype == 0 ) THEN WRITE ( * , '(6x, a)' ) '-- Variant using T-matrix' ELSE IF ( subtype == 1 ) THEN WRITE ( * , '(6x, a)' ) '-- Variant following Hunt et al. (2007)' ELSE IF ( subtype == 5 ) THEN WRITE ( * , '(6x, a)' ) '-- Offline mode' END IF WRITE ( * , '(14x, a, i5)' ) 'ensemble size:' , dim_ens IF ( subtype /= 5 ) WRITE ( * , '(6x, a, i5)' ) 'Assimilation interval:' , delt_obs WRITE ( * , '(10x, a, f5.2)' ) 'forgetting factor:' , forget IF ( model_error ) THEN WRITE ( * , '(6x, a, f5.2)' ) 'model error amplitude:' , model_err_amp END IF ELSE IF ( filtertype == 5 ) THEN WRITE ( * , '(21x, a)' ) 'Filter: LETKF' IF ( subtype == 0 ) THEN WRITE ( * , '(6x, a)' ) '-- Variant using T-matrix' ELSE IF ( subtype == 1 ) THEN WRITE ( * , '(6x, a)' ) '-- Variant following Hunt et al. (2007)' ELSE IF ( subtype == 5 ) THEN WRITE ( * , '(6x, a)' ) '-- Offline mode' END IF WRITE ( * , '(14x, a, i5)' ) 'ensemble size:' , dim_ens IF ( subtype /= 5 ) WRITE ( * , '(6x, a, i5)' ) 'Assimilation interval:' , delt_obs WRITE ( * , '(10x, a, f5.2)' ) 'forgetting factor:' , forget IF ( model_error ) THEN WRITE ( * , '(6x, a, f5.2)' ) 'model error amplitude:' , model_err_amp END IF ELSE IF ( filtertype == 6 ) THEN WRITE ( * , '(21x, a)' ) 'Filter: ESTKF' IF ( subtype == 0 ) THEN WRITE ( * , '(6x, a)' ) '-- Standard mode' ELSE IF ( subtype == 5 ) THEN WRITE ( * , '(6x, a)' ) '-- Offline mode' END IF WRITE ( * , '(14x, a, i5)' ) 'ensemble size:' , dim_ens IF ( subtype /= 5 ) WRITE ( * , '(6x, a, i5)' ) 'Assimilation interval:' , delt_obs WRITE ( * , '(10x, a, f5.2)' ) 'forgetting factor:' , forget IF ( model_error ) THEN WRITE ( * , '(6x, a, f5.2)' ) 'model error amplitude:' , model_err_amp END IF ELSE IF ( filtertype == 7 ) THEN WRITE ( * , '(21x, a)' ) 'Filter: LESTKF' IF ( subtype == 0 ) THEN WRITE ( * , '(6x, a)' ) '-- Standard mode' ELSE IF ( subtype == 5 ) THEN WRITE ( * , '(6x, a)' ) '-- Offline mode' END IF WRITE ( * , '(14x, a, i5)' ) 'ensemble size:' , dim_ens IF ( subtype /= 5 ) WRITE ( * , '(6x, a, i5)' ) 'Assimilation interval:' , delt_obs WRITE ( * , '(10x, a, f5.2)' ) 'forgetting factor:' , forget IF ( model_error ) THEN WRITE ( * , '(6x, a, f5.2)' ) 'model error amplitude:' , model_err_amp END IF END IF END SUBROUTINE init_info_pdaf !> This routine reads the namelist file with parameters !> controlling data assimilation with PDAF and outputs to !> screen. !> !> **Calling Sequence** !> *Called from:* `init_pdaf` SUBROUTINE read_config_pdaf () USE mod_parallel_pdaf , & ONLY : mype_ens USE mod_assimilation_pdaf , & ONLY : filtertype , subtype , dim_ens , delt_obs , & screen , forget , local_range , locweight , srange , istate_t , & istate_s , istate_u , istate_v , istate_ssh !> Namelist file CHARACTER ( lc ) :: nmlfile NAMELIST / pdaf_nml / filtertype , subtype , dim_ens , & delt_obs , screen , forget , local_range , locweight , & srange , istate_s , istate_t , istate_u , istate_v , istate_ssh ! **************************************************** ! ***   Initialize PDAF parameters from namelist   *** ! **************************************************** nmlfile = 'namelist.pdaf' OPEN ( 20 , file = nmlfile ) READ ( 20 , NML = pdaf_nml ) CLOSE ( 20 ) ! Print PDAF parameters to screen showconf : IF ( mype_ens == 0 ) THEN WRITE ( * , '(/1x,a)' ) '-- Overview of PDAF configuration --' WRITE ( * , '(3x,a)' ) 'PDAF [pdaf_nml]:' WRITE ( * , '(5x,a,i10)' ) 'filtertype   ' , filtertype WRITE ( * , '(5x,a,i10)' ) 'subtype      ' , subtype WRITE ( * , '(5x,a,i10)' ) 'dim_ens      ' , dim_ens WRITE ( * , '(5x,a,i10)' ) 'delt_obs     ' , delt_obs WRITE ( * , '(5x,a,i10)' ) 'screen       ' , screen WRITE ( * , '(5x,a,f10.2)' ) 'forget       ' , forget WRITE ( * , '(5x,a,es10.2)' ) 'local_range  ' , local_range WRITE ( * , '(5x,a,i10)' ) 'locweight    ' , locweight WRITE ( * , '(5x,a,es10.2)' ) 'srange       ' , srange WRITE ( * , '(5x,a,a)' ) 'istate_t   ' , istate_t WRITE ( * , '(5x,a,a)' ) 'istate_s   ' , istate_s WRITE ( * , '(5x,a,a)' ) 'istate_u   ' , istate_u WRITE ( * , '(5x,a,a)' ) 'istate_v   ' , istate_v WRITE ( * , '(5x,a,a)' ) 'istate_ssh ' , istate_ssh WRITE ( * , '(1x,a)' ) '-- End of PDAF configuration overview --' END IF showconf END SUBROUTINE read_config_pdaf END MODULE mod_util_pdaf","tags":"","loc":"sourcefile/mod_util_pdaf.f90.html"},{"title":"mod_kind_pdaf.F90 – NEMO4 PDAFOMI","text":"Contents Modules mod_kind_pdaf Source Code mod_kind_pdaf.F90 Source Code MODULE mod_kind_pdaf !>## Define real precision !> !>This module defines the kind of real and length of character strings !>for the PDAF call-back routines and interfaces. It is based on the NEMO !>module `par_kind.F90`. IMPLICIT NONE SAVE INTEGER , PARAMETER :: pdp = SELECTED_REAL_KIND ( 12 , 307 ) INTEGER , PARAMETER :: pwp = pdp INTEGER , PARAMETER :: lc = 256 END MODULE mod_kind_pdaf","tags":"","loc":"sourcefile/mod_kind_pdaf.f90.html"},{"title":"init_ens_pdaf.F90 – NEMO4 PDAFOMI","text":"Contents Subroutines init_ens_pdaf Source Code init_ens_pdaf.F90 Source Code !>##Ensemble Initialisation !>This routine calls the routines for initialising the ensemble. !> !>Separate calls are made for the 2D and 3D state variables to !>allow for differences in how these variables are initialised. !> !>The routine is called when the filter is initialized in !>`PDAF_filter_init`. !> !>The routine is called by all filter processes and !>initializes the ensemble for the *PE-local domain*. !> SUBROUTINE init_ens_pdaf ( filtertype , dim_p , dim_ens , state_p , Uinv , & ens_p , flag ) USE mod_kind_pdaf USE mod_parallel_pdaf , & ONLY : mype_ens USE mod_assimilation_pdaf , & ONLY : istate_ssh , istate_s , istate_t , istate_u , istate_v , & screen USE mod_statevector_pdaf , & ONLY : fill2d_ensarray , fill3d_ensarray IMPLICIT NONE !> Type of filter to initialize INTEGER , INTENT ( in ) :: filtertype !> PE-local state dimension INTEGER , INTENT ( in ) :: dim_p !> Size of ensemble INTEGER , INTENT ( in ) :: dim_ens !> PE-local model state !> It is not necessary to initialize the array 'state_p' for SEIK. !> It is available here only for convenience and can be used freely. REAL ( pwp ), INTENT ( inout ) :: state_p ( dim_p ) !> Array not referenced for SEIK REAL ( pwp ), INTENT ( inout ) :: Uinv ( dim_ens - 1 , dim_ens - 1 ) !> PE-local state ensemble REAL ( pwp ), INTENT ( out ) :: ens_p ( dim_p , dim_ens ) !> PDAF status flag INTEGER , INTENT ( inout ) :: flag IF ( screen > 0 ) THEN IF ( mype_ens == 0 ) THEN WRITE ( * , '(/1x,a)' ) '------- Reading Initial State --------' WRITE ( * , '(/1x,a)' ) 'Calling fill2d_ensarray' WRITE ( * , '(/9x, a, 3x, a,)' ) \"Initial state file:\" , TRIM ( istate_ssh ) END IF END IF CALL fill2d_ensarray ( istate_ssh , ens_p ) IF ( screen > 0 ) THEN IF ( mype_ens == 0 ) THEN WRITE ( * , '(/1x,a)' ) '------- Reading Initial State --------' WRITE ( * , '(/1x,a)' ) 'Calling fill3d_ensarray' WRITE ( * , '(/9x, a, 3x, a, 3x, a, 3x, a, 3x, a)' ) & \"Initial state files:\" , TRIM ( istate_t ), TRIM ( istate_s ), & TRIM ( istate_u ), TRIM ( istate_v ) END IF END IF CALL fill3d_ensarray ( istate_t , 'T' , ens_p ) CALL fill3d_ensarray ( istate_s , 'S' , ens_p ) CALL fill3d_ensarray ( istate_u , 'U' , ens_p ) CALL fill3d_ensarray ( istate_v , 'V' , ens_p ) END SUBROUTINE init_ens_pdaf","tags":"","loc":"sourcefile/init_ens_pdaf.f90.html"},{"title":"mod_assimilation_pdaf.F90 – NEMO4 PDAFOMI","text":"Contents Modules mod_assimilation_pdaf Source Code mod_assimilation_pdaf.F90 Source Code !>##Assimilation Parameters !>This module provides variables needed for the !>assimilation. !> !>See `mod_init_pdaf` for where many of these !>variables are initialised. !> MODULE mod_assimilation_pdaf USE mod_kind_pdaf IMPLICIT NONE SAVE !> Global model state dimension INTEGER :: dim_state !> Model state dimension for PE-local domain INTEGER :: dim_state_p !> Process-local number of observations INTEGER :: dim_obs_p !> Vector holding process-local observations REAL ( pwp ), ALLOCATABLE :: obs_p (:) !> Vector holding state-vector indices of observations INTEGER , ALLOCATABLE :: obs_index_p (:) !> Vector holding full vector of observations REAL ( pwp ), ALLOCATABLE :: obs_f (:) !> Array for full observation coordinates REAL ( pwp ), ALLOCATABLE :: coords_obs_f (:, :) !> Vector holding local state-vector indices of observations INTEGER , ALLOCATABLE :: obs_index_l (:) !> Vector holding distances of local observations REAL ( pwp ), ALLOCATABLE :: distance_l (:) !> Control application of model error LOGICAL :: model_error !> Amplitude for model error REAL ( pwp ) :: model_err_amp !> time step interval between assimilation steps INTEGER :: delt_obs !> Number of observations INTEGER :: dim_obs !> Control verbosity of PDAF !> (0) no outputs, (1) progess info, (2) add timings !> (3) debugging output INTEGER :: screen !> Size of ensemble for SEIK/LSEIK/EnKF/ETKF !> Number of EOFs to be used for SEEK INTEGER :: dim_ens !> Select filter algorithm: !> SEEK (0), SEIK (1), EnKF (2), LSEIK (3), ETKF (4) !> LETKF (5), ESTKF (6), LESTKF (7), NETF (9), LNETF (10) INTEGER :: filtertype !> Subtype of filter algorithm !>   SEEK: !>     (0) evolve normalized modes !>     (1) evolve scaled modes with unit U !>     (2) fixed basis (V); variable U matrix !>     (3) fixed covar matrix (V,U kept static) !>   SEIK: !>     (0) ensemble forecast; new formulation !>     (1) ensemble forecast; old formulation !>     (2) fixed error space basis !>     (3) fixed state covariance matrix !>     (4) SEIK with ensemble transformation !>   EnKF: !>     (0) analysis for large observation dimension !>     (1) analysis for small observation dimension !>   LSEIK: !>     (0) ensemble forecast; !>     (2) fixed error space basis !>     (3) fixed state covariance matrix !>     (4) LSEIK with ensemble transformation !>   ETKF: !>     (0) ETKF using T-matrix like SEIK !>     (1) ETKF following Hunt et al. (2007) !>       There are no fixed basis/covariance cases, as !>       these are equivalent to SEIK subtypes 2/3 !>   LETKF: !>     (0) LETKF using T-matrix like SEIK !>     (1) LETKF following Hunt et al. (2007) !>       There are no fixed basis/covariance cases, as !>       these are equivalent to LSEIK subtypes 2/3 !>   ESTKF: !>     (0) standard ESTKF !>       There are no fixed basis/covariance cases, as !>       these are equivalent to SEIK subtypes 2/3 !>   LESTKF: !>     (0) standard LESTKF !>       There are no fixed basis/covariance cases, as !>       these are equivalent to LSEIK subtypes 2/3 !>   NETF: !>     (0) standard NETF !>   LNETF: !>     (0) standard LNETF INTEGER :: subtype !> Perform incremental updating in LSEIK INTEGER :: incremental !> Number of time instances for smoother INTEGER :: dim_lag !> Type of forgetting factor INTEGER :: type_forget !> Forgetting factor for filter analysis REAL ( pwp ) :: forget !> dimension of bias vector INTEGER :: dim_bias !> Interval to perform re-diagonalization in SEEK INTEGER :: int_rediag !> Epsilon for gradient approx. in SEEK forecast REAL ( pwp ) :: epsilon !> Rank to be considered for inversion of HPH INTEGER :: rank_analysis_enkf !> Type of ensemble transformation !> SEIK/LSEIK: !> (0) use deterministic omega !> (1) use random orthonormal omega orthogonal to (1,...,1)&#94;T !> (2) use product of (0) with random orthonormal matrix with !>     eigenvector (1,...,1)&#94;T !> ETKF/LETKF with subtype=4: !> (0) use deterministic symmetric transformation !> (2) use product of (0) with random orthonormal matrix with !>     eigenvector (1,...,1)&#94;T !> ESTKF/LESTKF: !> (0) use deterministic omega !> (1) use random orthonormal omega orthogonal to (1,...,1)&#94;T !> (2) use product of (0) with random orthonormal matrix with !>     eigenvector (1,...,1)&#94;T !> NETF/LNETF: !> (0) use random orthonormal transformation orthogonal to (1,...,1)&#94;T !> (1) use identity transformation !>    ! LSEIK/LETKF/LESTKF INTEGER :: type_trans !> Range for local observation domain - NEMO grid REAL ( pwp ) :: local_range !> Type of localizing weighting of observations !>   (0) constant weight of 1 !>   (1) exponentially decreasing with SRANGE !>   (2) use 5th-order polynomial !>   (3) regulated localization of R with mean error variance !>   (4) regulated localization of R with single-point error variance INTEGER :: locweight !> Support range for 5th order polynomial - NEMO grid !>   or radius for 1/e for exponential weighting !>    ! SEIK-subtype4/LSEIK-subtype4/ESTKF/LESTKF REAL ( pwp ) :: srange !> Type of the transform matrix square-root !> (0) symmetric square root, (1) Cholesky decomposition INTEGER :: type_sqrt !> file for ssh initial state estimate CHARACTER ( lc ) :: istate_ssh !> file for t initial state estimate CHARACTER ( lc ) :: istate_t !> file for t initial state estimate CHARACTER ( lc ) :: istate_s !> file for u initial state estimate CHARACTER ( lc ) :: istate_u !> file for v initial state estimate CHARACTER ( lc ) :: istate_v !> For SEIK: Definition of ensemble covar matrix !> (0): Factor (r+1)&#94;-1 (or N&#94;-1) !> (1): Factor r&#94;-1 (or (N-1)&#94;-1) - real ensemble covar. !> This setting is only for the model part; The definition !> of P has also to be specified in PDAF_filter_init. !> Only for upward-compatibility of PDAF INTEGER :: covartype !> model time REAL ( pwp ) :: time !> Coordinates of local analysis domain REAL ( pwp ) :: coords_l ( 2 ) !> Indices of local analysis domain REAL ( pwp ), ALLOCATABLE :: indx_dom_l (:, :) !$OMP THREADPRIVATE(coords_l) END MODULE mod_assimilation_pdaf","tags":"","loc":"sourcefile/mod_assimilation_pdaf.f90.html"},{"title":"prepoststep_ens_pdaf.F90 – NEMO4 PDAFOMI","text":"Contents Subroutines prepoststep_ens_pdaf Source Code prepoststep_ens_pdaf.F90 Source Code !>##Controlling Pre- and Post-Processing, PDAF Output !>The routine is called for global filters (e.g. SEIK) !>before the analysis and after the ensemble transformation. !>For local filters (e.g. LSEIK) the routine is called !>before and after the loop over all local analysis !>domains. !> !>The routine provides full access to the state !>estimate and the state ensemble to the user. !>Thus, user-controlled pre- and poststep !>operations can be performed here. For example !>the forecast and the analysis states and ensemble !>covariance matrix can be analyzed, e.g. by !>computing the estimated variances. !>For the offline mode, this routine is the place !>in which the writing of the analysis ensemble !>can be performed. !> !>If a user considers to perform adjustments to the !>estimates (e.g. for balances), this routine is !>the right place for it. !> !>**Calling Sequence** !>*Called by:* `PDAF_get_state` (as U_prepoststep) !>*Called by:* `PDAF_X_update` (as U_prepoststep) !> SUBROUTINE prepoststep_ens_pdaf ( step , dim_p , dim_ens , dim_ens_p , dim_obs_p , & state_p , Uinv , ens_p , flag ) USE mod_kind_pdaf IMPLICIT NONE !> Current time step (negative for call after forecast) INTEGER , INTENT ( in ) :: step !> PE-local state dimension INTEGER , INTENT ( in ) :: dim_p !> Size of state ensemble INTEGER , INTENT ( in ) :: dim_ens !> PE-local size of ensemble INTEGER , INTENT ( in ) :: dim_ens_p !> PE-local dimension of observation vector INTEGER , INTENT ( in ) :: dim_obs_p !> PE-local forecast/analysis state !> The array 'state_p' is initialised and can be used !> freely here (not for SEEK!) REAL ( pwp ), INTENT ( inout ) :: state_p ( dim_p ) !> Inverse of matrix U REAL ( pwp ), INTENT ( inout ) :: Uinv ( dim_ens - 1 , dim_ens - 1 ) !> PE-local state ensemble REAL ( pwp ), INTENT ( inout ) :: ens_p ( dim_p , dim_ens ) !> PDAF status flag INTEGER , INTENT ( in ) :: flag WRITE ( * , '(/1x,a)' ) 'Insert prepoststep routines here. ' END SUBROUTINE prepoststep_ens_pdaf","tags":"","loc":"sourcefile/prepoststep_ens_pdaf.f90.html"},{"title":"next_observation_pdaf.F90 – NEMO4 PDAFOMI","text":"Contents Subroutines next_observation_pdaf Source Code next_observation_pdaf.F90 Source Code !>##Determining the Next Analysis Step !>The subroutine is called before each forecast phase !>by `PDAF_get_state`. It has to initialize the number !>of time steps until the next available observation !>(`nsteps`). It indicates if the data assimilation process !>is completed such that the ensemble loop in the model !>routine can be exited. !> !>The routine is called by all processes. !> !>**Calling Sequence** !>*Called from:* `PDAF_get_state` (as U_next_obs) !> SUBROUTINE next_observation_pdaf ( stepnow , nsteps , doexit , time ) USE mod_kind_pdaf USE mod_assimilation_pdaf , & ONLY : delt_obs USE mod_parallel_pdaf , & ONLY : mype_ens USE in_out_manager , & ONLY : nitend IMPLICIT NONE !> Number of the current time step INTEGER , INTENT ( in ) :: stepnow !> Number of time steps until next obs INTEGER , INTENT ( out ) :: nsteps !> Whether to exit forecasting (1 for exit) INTEGER , INTENT ( out ) :: doexit !> Current model (physical) time REAL ( pwp ), INTENT ( out ) :: time ! ******************************************************* ! *** Set number of time steps until next observation *** ! ******************************************************* ! Not used in this implementation time = 0.0 IF ( stepnow + delt_obs <= nitend ) THEN ! *** During the assimilation process *** nsteps = delt_obs ! This assumes a constant time step interval doexit = 0 ! Not used in this implementation IF ( mype_ens == 0 ) WRITE ( * , '(i7, 3x, a, i7)' ) & stepnow , 'Next observation at time step' , stepnow + nsteps ELSE ! *** End of assimilation process *** nsteps = 0 ! No more steps doexit = 1 ! Not used in this implementation IF ( mype_ens == 0 ) WRITE ( * , '(i7, 3x, a)' ) & stepnow , 'No more observations - end assimilation' END IF END SUBROUTINE next_observation_pdaf","tags":"","loc":"sourcefile/next_observation_pdaf.f90.html"},{"title":"distribute_state_pdaf – NEMO4 PDAFOMI","text":"subroutine distribute_state_pdaf(dim_p, state_p) Uses mod_kind_pdaf mod_statevector_pdaf dom_oce oce par_oce lbclnk Distributing the statevector variables The routine has to initialize the fields of the\nmodel from the statevector of PDAF. The routine is executed by each process that is\nparticipating in the model integrations. Calling Sequence Called from: PDAF_get_state (as U_dist_state) Called from: PDAF_assimilate_X (as U_coll_state) Arguments Type Intent Optional Attributes Name integer, intent(in) :: dim_p PE-local state dimension real(kind=pwp), intent(inout) :: state_p (dim_p) PE-local state vector Contents Variables i i0 j j0 k Source Code distribute_state_pdaf Variables Type Visibility Attributes Name Initial integer, public :: i Counters integer, public :: i0 Start index for MPI subdomain integer, public :: j Counters integer, public :: j0 Start index for MPI subdomain integer, public :: k Counters Source Code SUBROUTINE distribute_state_pdaf ( dim_p , state_p ) USE mod_kind_pdaf USE mod_statevector_pdaf , & ONLY : mpi_subd_lat , mpi_subd_lon , mpi_subd_vert , ssh_p_offset , & t_p_offset , s_p_offset , u_p_offset , v_p_offset USE dom_oce , & ONLY : nldj , nldi USE oce , & ONLY : sshb , tsb , ub , vb USE par_oce , & ONLY : jp_tem , jp_sal , jpi , jpj , jpk USE lbclnk , & ONLY : lbc_lnk , lbc_lnk_multi IMPLICIT NONE !> PE-local state dimension INTEGER , INTENT ( in ) :: dim_p !> PE-local state vector REAL ( pwp ), INTENT ( inout ) :: state_p ( dim_p ) !> Counters INTEGER :: i , j , k !> Start index for MPI subdomain INTEGER :: i0 , j0 ! Set the starting index after the halo region j0 = nldj - 1 i0 = nldi - 1 ! ************************************ ! Distribute state vector 2d variables ! ************************************ ! SSH DO j = 1 , mpi_subd_lat DO i = 1 , mpi_subd_lon sshb ( i + i0 , j + j0 ) = state_p ( i + ( j - 1 ) * mpi_subd_lon & + ssh_p_offset ) END DO END DO ! Fill halo regions CALL lbc_lnk ( 'distribute_state_pdaf' , sshb , 'T' , 1. ) ! ************************************ ! Distribute state vector 3d variables ! ************************************ ! T DO k = 1 , mpi_subd_vert DO j = 1 , mpi_subd_lat DO i = 1 , mpi_subd_lon tsb ( i + i0 , j + j0 , k , jp_tem ) = state_p ( i + ( j - 1 ) * mpi_subd_lon & + ( k - 1 ) * mpi_subd_lat * mpi_subd_lon + t_p_offset ) END DO END DO END DO ! S DO k = 1 , mpi_subd_vert DO j = 1 , mpi_subd_lat DO i = 1 , mpi_subd_lon tsb ( i + i0 , j + j0 , k , jp_sal ) = state_p ( i + ( j - 1 ) * mpi_subd_lon & + ( k - 1 ) * mpi_subd_lat * mpi_subd_lon + s_p_offset ) END DO END DO END DO ! Fill halo regions CALL lbc_lnk_multi ( 'distribute_state_pdaf' , tsb (:, :, :, jp_tem ), 'T' , & 1. , tsb (:, :, :, jp_sal ), 'T' , 1. ) ! U DO k = 1 , mpi_subd_vert DO j = 1 , mpi_subd_lat DO i = 1 , mpi_subd_lon ub ( i + i0 , j + j0 , k ) = state_p ( i + ( j - 1 ) * mpi_subd_lon + & ( k - 1 ) * mpi_subd_lat * mpi_subd_lon + u_p_offset ) END DO END DO END DO ! V DO k = 1 , mpi_subd_vert DO j = 1 , mpi_subd_lat DO i = 1 , mpi_subd_lon vb ( i + i0 , j + j0 , k ) = state_p ( i + ( j - 1 ) * mpi_subd_lon + & ( k - 1 ) * mpi_subd_lat * mpi_subd_lon + v_p_offset ) END DO END DO END DO ! Fill halo regions CALL lbc_lnk_multi ( 'distribute_state_pdaf' , ub , 'U' , - 1. , vb , 'V' , - 1. ) END SUBROUTINE distribute_state_pdaf","tags":"","loc":"proc/distribute_state_pdaf.html"},{"title":"init_ens_pdaf – NEMO4 PDAFOMI","text":"subroutine init_ens_pdaf(filtertype, dim_p, dim_ens, state_p, Uinv, ens_p, flag) Uses mod_kind_pdaf mod_parallel_pdaf mod_assimilation_pdaf mod_statevector_pdaf Ensemble Initialisation This routine calls the routines for initialising the ensemble. Separate calls are made for the 2D and 3D state variables to\nallow for differences in how these variables are initialised. The routine is called when the filter is initialized in PDAF_filter_init . The routine is called by all filter processes and\ninitializes the ensemble for the PE-local domain . Arguments Type Intent Optional Attributes Name integer, intent(in) :: filtertype Type of filter to initialize integer, intent(in) :: dim_p PE-local state dimension integer, intent(in) :: dim_ens Size of ensemble real(kind=pwp), intent(inout) :: state_p (dim_p) PE-local model state\n It is not necessary to initialize the array ‘state_p’ for SEIK.\n It is available here only for convenience and can be used freely. real(kind=pwp), intent(inout) :: Uinv (dim_ens-1,dim_ens-1) Array not referenced for SEIK real(kind=pwp), intent(out) :: ens_p (dim_p,dim_ens) PE-local state ensemble integer, intent(inout) :: flag PDAF status flag Contents Source Code init_ens_pdaf Source Code SUBROUTINE init_ens_pdaf ( filtertype , dim_p , dim_ens , state_p , Uinv , & ens_p , flag ) USE mod_kind_pdaf USE mod_parallel_pdaf , & ONLY : mype_ens USE mod_assimilation_pdaf , & ONLY : istate_ssh , istate_s , istate_t , istate_u , istate_v , & screen USE mod_statevector_pdaf , & ONLY : fill2d_ensarray , fill3d_ensarray IMPLICIT NONE !> Type of filter to initialize INTEGER , INTENT ( in ) :: filtertype !> PE-local state dimension INTEGER , INTENT ( in ) :: dim_p !> Size of ensemble INTEGER , INTENT ( in ) :: dim_ens !> PE-local model state !> It is not necessary to initialize the array 'state_p' for SEIK. !> It is available here only for convenience and can be used freely. REAL ( pwp ), INTENT ( inout ) :: state_p ( dim_p ) !> Array not referenced for SEIK REAL ( pwp ), INTENT ( inout ) :: Uinv ( dim_ens - 1 , dim_ens - 1 ) !> PE-local state ensemble REAL ( pwp ), INTENT ( out ) :: ens_p ( dim_p , dim_ens ) !> PDAF status flag INTEGER , INTENT ( inout ) :: flag IF ( screen > 0 ) THEN IF ( mype_ens == 0 ) THEN WRITE ( * , '(/1x,a)' ) '------- Reading Initial State --------' WRITE ( * , '(/1x,a)' ) 'Calling fill2d_ensarray' WRITE ( * , '(/9x, a, 3x, a,)' ) \"Initial state file:\" , TRIM ( istate_ssh ) END IF END IF CALL fill2d_ensarray ( istate_ssh , ens_p ) IF ( screen > 0 ) THEN IF ( mype_ens == 0 ) THEN WRITE ( * , '(/1x,a)' ) '------- Reading Initial State --------' WRITE ( * , '(/1x,a)' ) 'Calling fill3d_ensarray' WRITE ( * , '(/9x, a, 3x, a, 3x, a, 3x, a, 3x, a)' ) & \"Initial state files:\" , TRIM ( istate_t ), TRIM ( istate_s ), & TRIM ( istate_u ), TRIM ( istate_v ) END IF END IF CALL fill3d_ensarray ( istate_t , 'T' , ens_p ) CALL fill3d_ensarray ( istate_s , 'S' , ens_p ) CALL fill3d_ensarray ( istate_u , 'U' , ens_p ) CALL fill3d_ensarray ( istate_v , 'V' , ens_p ) END SUBROUTINE init_ens_pdaf","tags":"","loc":"proc/init_ens_pdaf.html"},{"title":"prepoststep_ens_pdaf – NEMO4 PDAFOMI","text":"subroutine prepoststep_ens_pdaf(step, dim_p, dim_ens, dim_ens_p, dim_obs_p, state_p, Uinv, ens_p, flag) Uses mod_kind_pdaf Controlling Pre- and Post-Processing, PDAF Output The routine is called for global filters (e.g. SEIK)\nbefore the analysis and after the ensemble transformation.\nFor local filters (e.g. LSEIK) the routine is called\nbefore and after the loop over all local analysis\ndomains. The routine provides full access to the state\nestimate and the state ensemble to the user.\nThus, user-controlled pre- and poststep\noperations can be performed here. For example\nthe forecast and the analysis states and ensemble\ncovariance matrix can be analyzed, e.g. by\ncomputing the estimated variances.\nFor the offline mode, this routine is the place\nin which the writing of the analysis ensemble\ncan be performed. If a user considers to perform adjustments to the\nestimates (e.g. for balances), this routine is\nthe right place for it. Calling Sequence Called by: PDAF_get_state (as U_prepoststep) Called by: PDAF_X_update (as U_prepoststep) Arguments Type Intent Optional Attributes Name integer, intent(in) :: step Current time step (negative for call after forecast) integer, intent(in) :: dim_p PE-local state dimension integer, intent(in) :: dim_ens Size of state ensemble integer, intent(in) :: dim_ens_p PE-local size of ensemble integer, intent(in) :: dim_obs_p PE-local dimension of observation vector real(kind=pwp), intent(inout) :: state_p (dim_p) PE-local forecast/analysis state\n The array ‘state_p’ is initialised and can be used\n freely here (not for SEEK!) real(kind=pwp), intent(inout) :: Uinv (dim_ens-1,dim_ens-1) Inverse of matrix U real(kind=pwp), intent(inout) :: ens_p (dim_p,dim_ens) PE-local state ensemble integer, intent(in) :: flag PDAF status flag Contents Source Code prepoststep_ens_pdaf Source Code SUBROUTINE prepoststep_ens_pdaf ( step , dim_p , dim_ens , dim_ens_p , dim_obs_p , & state_p , Uinv , ens_p , flag ) USE mod_kind_pdaf IMPLICIT NONE !> Current time step (negative for call after forecast) INTEGER , INTENT ( in ) :: step !> PE-local state dimension INTEGER , INTENT ( in ) :: dim_p !> Size of state ensemble INTEGER , INTENT ( in ) :: dim_ens !> PE-local size of ensemble INTEGER , INTENT ( in ) :: dim_ens_p !> PE-local dimension of observation vector INTEGER , INTENT ( in ) :: dim_obs_p !> PE-local forecast/analysis state !> The array 'state_p' is initialised and can be used !> freely here (not for SEEK!) REAL ( pwp ), INTENT ( inout ) :: state_p ( dim_p ) !> Inverse of matrix U REAL ( pwp ), INTENT ( inout ) :: Uinv ( dim_ens - 1 , dim_ens - 1 ) !> PE-local state ensemble REAL ( pwp ), INTENT ( inout ) :: ens_p ( dim_p , dim_ens ) !> PDAF status flag INTEGER , INTENT ( in ) :: flag WRITE ( * , '(/1x,a)' ) 'Insert prepoststep routines here. ' END SUBROUTINE prepoststep_ens_pdaf","tags":"","loc":"proc/prepoststep_ens_pdaf.html"},{"title":"next_observation_pdaf – NEMO4 PDAFOMI","text":"subroutine next_observation_pdaf(stepnow, nsteps, doexit, time) Uses mod_kind_pdaf mod_assimilation_pdaf mod_parallel_pdaf in_out_manager Determining the Next Analysis Step The subroutine is called before each forecast phase\nby PDAF_get_state . It has to initialize the number\nof time steps until the next available observation\n( nsteps ). It indicates if the data assimilation process\nis completed such that the ensemble loop in the model\nroutine can be exited. The routine is called by all processes. Calling Sequence Called from: PDAF_get_state (as U_next_obs) Arguments Type Intent Optional Attributes Name integer, intent(in) :: stepnow Number of the current time step integer, intent(out) :: nsteps Number of time steps until next obs integer, intent(out) :: doexit Whether to exit forecasting (1 for exit) real(kind=pwp), intent(out) :: time Current model (physical) time Contents Source Code next_observation_pdaf Source Code SUBROUTINE next_observation_pdaf ( stepnow , nsteps , doexit , time ) USE mod_kind_pdaf USE mod_assimilation_pdaf , & ONLY : delt_obs USE mod_parallel_pdaf , & ONLY : mype_ens USE in_out_manager , & ONLY : nitend IMPLICIT NONE !> Number of the current time step INTEGER , INTENT ( in ) :: stepnow !> Number of time steps until next obs INTEGER , INTENT ( out ) :: nsteps !> Whether to exit forecasting (1 for exit) INTEGER , INTENT ( out ) :: doexit !> Current model (physical) time REAL ( pwp ), INTENT ( out ) :: time ! ******************************************************* ! *** Set number of time steps until next observation *** ! ******************************************************* ! Not used in this implementation time = 0.0 IF ( stepnow + delt_obs <= nitend ) THEN ! *** During the assimilation process *** nsteps = delt_obs ! This assumes a constant time step interval doexit = 0 ! Not used in this implementation IF ( mype_ens == 0 ) WRITE ( * , '(i7, 3x, a, i7)' ) & stepnow , 'Next observation at time step' , stepnow + nsteps ELSE ! *** End of assimilation process *** nsteps = 0 ! No more steps doexit = 1 ! Not used in this implementation IF ( mype_ens == 0 ) WRITE ( * , '(i7, 3x, a)' ) & stepnow , 'No more observations - end assimilation' END IF END SUBROUTINE next_observation_pdaf","tags":"","loc":"proc/next_observation_pdaf.html"},{"title":"init_pdaf – NEMO4 PDAFOMI","text":"public subroutine init_pdaf() Uses mod_parallel_pdaf mod_assimilation_pdaf mod_statevector_pdaf mod_util_pdaf This routine collects the initialization of variables for PDAF.\n In addition, the initialization routine PDAF_init is called\n such that the internal initialization of PDAF is performed.\n This variant is for the online mode of PDAF. The ensemble is initialised in init_ens_pdaf , and is then\n distributed to the model in distribute_state_pdaf . The statevector dimension, and the offset and dimension of the\n statevector variables is calculated in calc_statevector_dim . Much of the initialisation is read from a PDAF-specific namelist.\n This is performed in read_config_pdaf . Calling Sequence Called from: nemogcm.F90 Calls: calc_statevector_dim Calls: read_config_pdaf Calls: init_pdaf_info Calls: PDAF_init Calls: PDAF_get_state Arguments None Contents Variables doexit filter_param_i filter_param_r status_pdaf steps timenow Source Code init_pdaf Variables Type Visibility Attributes Name Initial integer, public :: doexit Not used in this implementation integer, public :: filter_param_i (7) Integer parameter array for filter real(kind=pwp), public :: filter_param_r (2) Real parameter array for filter integer, public :: status_pdaf PDAF status flag integer, public :: steps Not used in this implementation real(kind=pwp), public :: timenow Not used in this implementation Source Code SUBROUTINE init_pdaf () USE mod_parallel_pdaf , & ONLY : n_modeltasks , task_id , COMM_model , COMM_filter , & COMM_couple , mype_ens , filterpe , abort_parallel USE mod_assimilation_pdaf , & ONLY : dim_state_p , screen , filtertype , subtype , dim_ens , & incremental , covartype , type_forget , forget , rank_analysis_enkf , & type_trans , type_sqrt , delt_obs , locweight , local_range , srange USE mod_statevector_pdaf , & ONLY : calc_statevector_dim USE mod_util_pdaf , & ONLY : init_info_pdaf , read_config_pdaf !> Integer parameter array for filter INTEGER :: filter_param_i ( 7 ) !> Real parameter array for filter REAL ( pwp ) :: filter_param_r ( 2 ) !> PDAF status flag INTEGER :: status_pdaf !> Not used in this implementation INTEGER :: doexit , steps !> Not used in this implementation REAL ( pwp ) :: timenow ! Ensemble initialization EXTERNAL :: init_ens_pdaf ! Determine how long until next observation EXTERNAL :: next_observation_pdaf ! Routine to distribute a state vector to model fields EXTERNAL :: distribute_state_pdaf ! User supplied pre/poststep routine EXTERNAL :: prepoststep_ens_pdaf ! *************************** ! ***   Initialize PDAF   *** ! *************************** IF ( mype_ens == 0 ) THEN WRITE ( * , '(/1x,a)' ) 'INITIALIZE PDAF - ONLINE MODE' END IF ! Compute dimension of local statevector. Also compute offset ! and dimension of local state variables CALL calc_statevector_dim ( dim_state_p ) ! ********************************************************** ! ***   CONTROL OF PDAF - used in call to PDAF_init      *** ! ********************************************************** ! *** IO options *** screen = 2 ! Write screen output (1) for output, (2) add timings ! *** Filter specific variables filtertype = 5 ! Type of filter !   (1) SEIK !   (2) EnKF !   (3) LSEIK !   (4) ETKF !   (5) LETKF !   (6) ESTKF !   (7) LESTKF dim_ens = n_modeltasks ! Size of ensemble for all ensemble filters !   We use n_modeltasks here, initialized in init_parallel_pdaf subtype = 0 ! subtype of filter: !   ESTKF: !     (0) Standard form of ESTKF !   LESTKF: !     (0) Standard form of LESTKF type_trans = 0 ! Type of ensemble transformation !   SEIK/LSEIK and ESTKF/LESTKF: !     (0) use deterministic omega !     (1) use random orthonormal omega orthogonal to (1,...,1)&#94;T !     (2) use product of (0) with random orthonormal matrix with !         eigenvector (1,...,1)&#94;T !   ETKF/LETKF: !     (0) use deterministic symmetric transformation !     (2) use product of (0) with random orthonormal matrix with !         eigenvector (1,...,1)&#94;T type_forget = 0 ! Type of forgetting factor in SEIK/LSEIK/ETKF/LETKF/ESTKF/LESTKF !   (0) fixed !   (1) global adaptive !   (2) local adaptive for LSEIK/LETKF/LESTKF forget = 1.0 ! Forgetting factor type_sqrt = 0 ! Type of transform matrix square-root !   (0) symmetric square root, (1) Cholesky decomposition incremental = 0 ! (1) to perform incremental updating (only in SEIK/LSEIK!) covartype = 1 ! Definition of factor in covar. matrix used in SEIK !   (0) for dim_ens&#94;-1 (old SEIK) !   (1) for (dim_ens-1)&#94;-1 (real ensemble covariance matrix) !   This parameter has also to be set internally in PDAF_init. rank_analysis_enkf = 0 ! rank to be considered for inversion of HPH ! in analysis of EnKF; (0) for analysis w/o eigendecomposition ! ********************************************************************* ! ***   Settings for analysis steps  - used in call-back routines   *** ! ********************************************************************* ! *** Forecast length (time interval between analysis steps) *** delt_obs = 24 ! Number of time steps between analysis/assimilation steps ! *** Localization settings locweight = 0 ! Type of localizating weighting !   (0) constant weight of 1 !   (1) exponentially decreasing with SRANGE !   (2) use 5th-order polynomial !   (3) regulated localization of R with mean error variance !   (4) regulated localization of R with single-point error variance local_range = 0 ! Range in grid points for observation domain in local filters srange = local_range ! Support range for 5th-order polynomial ! or range for 1/e for exponential weighting ! ************************** ! Namelist and screen output ! ************************** ! Read namelist file for PDAF CALL read_config_pdaf () ! Screen output for PDAF parameters IF ( mype_ens == 0 ) CALL init_info_pdaf () ! ***************************************************** ! *** Call PDAF initialization routine on all PEs.  *** ! ***                                               *** ! *** Here, the full selection of filters is        *** ! *** implemented. In a real implementation, one    *** ! *** reduce this to selected filters.              *** ! ***                                               *** ! *** For all filters, first the arrays of integer  *** ! *** and real number parameters are initialized.   *** ! *** Subsequently, PDAF_init is called.            *** ! ***************************************************** whichinit : IF ( filtertype == 2 ) THEN ! *** EnKF with Monte Carlo init *** filter_param_i ( 1 ) = dim_state_p ! State dimension filter_param_i ( 2 ) = dim_ens ! Size of ensemble filter_param_i ( 3 ) = rank_analysis_enkf ! Rank of speudo-inverse in analysis filter_param_i ( 4 ) = incremental ! Whether to perform incremental analysis filter_param_i ( 5 ) = 0 ! Smoother lag (not implemented here) filter_param_r ( 1 ) = forget ! Forgetting factor CALL PDAF_init ( filtertype , subtype , 0 , & filter_param_i , 6 , & filter_param_r , 2 , & COMM_model , COMM_filter , COMM_couple , & task_id , n_modeltasks , filterpe , init_ens_pdaf , & screen , status_pdaf ) ELSE ! *** All other filters                       *** ! *** SEIK, LSEIK, ETKF, LETKF, ESTKF, LESTKF *** filter_param_i ( 1 ) = dim_state_p ! State dimension filter_param_i ( 2 ) = dim_ens ! Size of ensemble filter_param_i ( 3 ) = 0 ! Smoother lag (not implemented here) filter_param_i ( 4 ) = incremental ! Whether to perform incremental analysis filter_param_i ( 5 ) = type_forget ! Type of forgetting factor filter_param_i ( 6 ) = type_trans ! Type of ensemble transformation filter_param_i ( 7 ) = type_sqrt ! Type of transform square-root (SEIK-sub4/ESTKF) filter_param_r ( 1 ) = forget ! Forgetting factor CALL PDAF_init ( filtertype , subtype , 0 , & filter_param_i , 7 , & filter_param_r , 2 , & COMM_model , COMM_filter , COMM_couple , & task_id , n_modeltasks , filterpe , init_ens_pdaf , & screen , status_pdaf ) END IF whichinit ! *** Check whether initialization of PDAF was successful *** IF ( status_pdaf /= 0 ) THEN WRITE ( * , '(/1x,a6,i3,a43,i4,a1/)' ) & 'ERROR ' , status_pdaf , & ' in initialization of PDAF - stopping! (PE ' , mype_ens , ')' CALL abort_parallel () END IF ! ********************************** ! *** Prepare ensemble forecasts *** ! ********************************** CALL PDAF_get_state ( steps , timenow , doexit , next_observation_pdaf , & distribute_state_pdaf , prepoststep_ens_pdaf , status_pdaf ) END SUBROUTINE init_pdaf","tags":"","loc":"proc/init_pdaf.html"},{"title":"abort_parallel – NEMO4 PDAFOMI","text":"public subroutine abort_parallel() Terminate the MPI execution environment. Arguments None Contents Source Code abort_parallel Source Code SUBROUTINE abort_parallel () CALL MPI_Abort ( MPI_COMM_WORLD , 1 , MPIerr ) END SUBROUTINE abort_parallel","tags":"","loc":"proc/abort_parallel.html"},{"title":"init_parallel_pdaf – NEMO4 PDAFOMI","text":"public subroutine init_parallel_pdaf(screen, mpi_comm) Split the MPI communicator initialised by XIOS into MODEL,\n FILTER and COUPLE communicators, return MODEL communicator. Calling Sequence Called from: lib_mpp.F90 Calls: MPI_Comm_size Calls: MPI_Comm_rank Calls: MPI_Comm_split Calls: MPI_Barrier Arguments Type Intent Optional Attributes Name integer, intent(in) :: screen Whether screen information is shown integer, intent(inout) :: mpi_comm Communicator after XIOS splitting Contents Variables color_couple i j my_color nmlfile pe_index tasks Source Code init_parallel_pdaf Variables Type Visibility Attributes Name Initial integer, public :: color_couple Variables for communicator-splitting integer, public :: i Counters integer, public :: j Counters integer, public :: my_color Variables for communicator-splitting character(len=lc), public :: nmlfile namelist file integer, public :: pe_index Index of PE integer, public :: tasks Number of model tasks Source Code SUBROUTINE init_parallel_pdaf ( screen , mpi_comm ) !> Whether screen information is shown INTEGER , INTENT ( in ) :: screen !> Communicator after XIOS splitting INTEGER , INTENT ( inout ) :: mpi_comm !> Counters INTEGER :: i , j !> Index of PE INTEGER :: pe_index !> Variables for communicator-splitting INTEGER :: my_color , color_couple !> Number of model tasks INTEGER :: tasks !> namelist file CHARACTER ( lc ) :: nmlfile ! Number of ensemble members, supplied by PDAF namelist NAMELIST / tasks_nml / tasks ! Read namelist for number of model tasks nmlfile = 'namelist.pdaf' OPEN ( 20 , file = nmlfile ) READ ( 20 , NML = tasks_nml ) CLOSE ( 20 ) n_modeltasks = tasks ! ***              COMM_ENSEMBLE                *** ! *** Generate communicator for ensemble runs   *** ! *** only used to generate model communicators *** COMM_ensemble = mpi_comm CALL MPI_Comm_Size ( COMM_ensemble , npes_ens , MPIerr ) CALL MPI_Comm_Rank ( COMM_ensemble , mype_ens , MPIerr ) ! Initialize communicators for ensemble evaluations IF ( mype_ens == 0 ) THEN WRITE ( * , '(/1x, a)' ) 'Initialize communicators for assimilation with PDAF' END IF ! Store # PEs per ensemble member. Used for info on PE 0 and for ! generation of model communicators on other PEs ALLOCATE ( local_npes_model ( n_modeltasks )) local_npes_model = FLOOR ( REAL ( npes_ens ) / REAL ( n_modeltasks )) DO i = 1 , ( npes_ens - n_modeltasks * local_npes_model ( 1 )) local_npes_model ( i ) = local_npes_model ( i ) + 1 END DO ! ***              COMM_MODEL               *** ! *** Generate communicators for model runs *** pe_index = 0 doens1 : DO i = 1 , n_modeltasks DO j = 1 , local_npes_model ( i ) IF ( mype_ens == pe_index ) THEN task_id = i EXIT doens1 END IF pe_index = pe_index + 1 END DO END DO doens1 CALL MPI_Comm_split ( COMM_ensemble , task_id , mype_ens , & COMM_model , MPIerr ) ! Re-initialize PE information according to model communicator CALL MPI_Comm_Size ( COMM_model , npes_model , MPIerr ) CALL MPI_Comm_Rank ( COMM_model , mype_model , MPIerr ) IF ( screen > 1 ) then WRITE ( * , * ) 'MODEL: mype(w)= ' , mype_ens , '; model task: ' , task_id , & '; mype(m)= ' , mype_model , '; npes(m)= ' , npes_model END IF ! Init flag FILTERPE (all PEs of model task 1) IF ( task_id == 1 ) THEN filterpe = . TRUE . ELSE filterpe = . FALSE . END IF ! ***         COMM_FILTER                 *** ! *** Generate communicator for filter    *** IF ( filterpe ) THEN my_color = task_id ELSE my_color = MPI_UNDEFINED END IF CALL MPI_Comm_split ( COMM_ensemble , my_color , mype_ens , & COMM_filter , MPIerr ) ! Initialize PE information according to filter communicator IF ( filterpe ) THEN CALL MPI_Comm_Size ( COMM_filter , npes_filter , MPIerr ) CALL MPI_Comm_Rank ( COMM_filter , mype_filter , MPIerr ) END IF ! ***              COMM_COUPLE                 *** ! *** Generate communicators for communication *** ! *** between model and filter PEs             *** color_couple = mype_model + 1 CALL MPI_Comm_split ( COMM_ensemble , color_couple , mype_ens , & COMM_couple , MPIerr ) ! Initialize PE information according to coupling communicator CALL MPI_Comm_Size ( COMM_couple , npes_couple , MPIerr ) CALL MPI_Comm_Rank ( COMM_couple , mype_couple , MPIerr ) IF ( screen > 0 ) THEN IF ( mype_ens == 0 ) THEN WRITE ( * , '(/18x, a)' ) 'PE configuration:' WRITE ( * , '(2x, a6, a9, a10, a14, a13, /2x, a5, a9, a7, a7, a7, a7, a7, /2x, a)' ) & 'world' , 'filter' , 'model' , 'couple' , 'filterPE' , & 'rank' , 'rank' , 'task' , 'rank' , 'task' , 'rank' , 'T/F' , & '----------------------------------------------------------' END IF CALL MPI_Barrier ( COMM_ensemble , MPIerr ) IF ( task_id == 1 ) THEN WRITE ( * , '(2x, i4, 4x, i4, 4x, i3, 4x, i3, 4x, i3, 4x, i3, 5x, l3)' ) & mype_ens , mype_filter , task_id , mype_model , color_couple , & mype_couple , filterpe END IF IF ( task_id > 1 ) THEN WRITE ( * , '(2x, i4, 12x, i3, 4x, i3, 4x, i3, 4x, i3, 5x, l3)' ) & mype_ens , task_id , mype_model , color_couple , mype_couple , filterpe END IF CALL MPI_Barrier ( COMM_ensemble , MPIerr ) IF ( mype_ens == 0 ) WRITE ( * , '(/a)' ) '' END IF ! **************************************************** ! *** Re-initialize model equivalent to COMM_model *** ! **************************************************** mpi_comm = COMM_model END SUBROUTINE init_parallel_pdaf","tags":"","loc":"proc/init_parallel_pdaf.html"},{"title":"calc_mpi_dim – NEMO4 PDAFOMI","text":"public subroutine calc_mpi_dim() Uses par_oce dom_oce This routine calculates the dimensions of the MPI subdomain\n that is used to fill the local statevector. Arguments None Contents Source Code calc_mpi_dim Source Code SUBROUTINE calc_mpi_dim () USE par_oce , ONLY : jpk USE dom_oce , ONLY : nldi , nldj , nlei , nlej mpi_subd_lon = nlei - nldi + 1 mpi_subd_lat = nlej - nldj + 1 mpi_subd_vert = jpk END SUBROUTINE calc_mpi_dim","tags":"","loc":"proc/calc_mpi_dim.html"},{"title":"calc_offset – NEMO4 PDAFOMI","text":"public subroutine calc_offset() This routine calculates the offset values for each of the\n local statevector variables. It then stores the 2d/3d offset\n values in separate arrays. Arguments None Contents Source Code calc_offset Source Code SUBROUTINE calc_offset () ! Compute local statevector dimensions in case not already done CALL calc_statevar_dim () ssh_p_offset = 0 t_p_offset = ssh_p_offset + ssh_p_dim s_p_offset = t_p_offset + t_p_dim u_p_offset = s_p_offset + s_p_dim v_p_offset = u_p_offset + u_p_dim END SUBROUTINE calc_offset","tags":"","loc":"proc/calc_offset.html"},{"title":"calc_statevar_dim – NEMO4 PDAFOMI","text":"public subroutine calc_statevar_dim() This routine calculates the dimension of each of the local\n statevector variables. Arguments None Contents Source Code calc_statevar_dim Source Code SUBROUTINE calc_statevar_dim () ! Compute MPI subdomain dimensions in case not already done CALL calc_mpi_dim () ssh_p_dim = mpi_subd_lat * mpi_subd_lon t_p_dim = mpi_subd_lat * mpi_subd_lon * mpi_subd_vert s_p_dim = mpi_subd_lat * mpi_subd_lon * mpi_subd_vert u_p_dim = mpi_subd_lat * mpi_subd_lon * mpi_subd_vert v_p_dim = mpi_subd_lat * mpi_subd_lon * mpi_subd_vert END SUBROUTINE calc_statevar_dim","tags":"","loc":"proc/calc_statevar_dim.html"},{"title":"calc_statevector_dim – NEMO4 PDAFOMI","text":"public subroutine calc_statevector_dim(dim_p) This routine calculates the dimension of the local statevector. Arguments Type Intent Optional Attributes Name integer, intent(inout) :: dim_p Local statevector dimension Contents Source Code calc_statevector_dim Source Code SUBROUTINE calc_statevector_dim ( dim_p ) !> Local statevector dimension INTEGER , INTENT ( inout ) :: dim_p ! Calculate state variable dimensions in case not already done CALL calc_statevar_dim () dim_p = ssh_p_dim + t_p_dim + s_p_dim + u_p_dim + v_p_dim END SUBROUTINE calc_statevector_dim","tags":"","loc":"proc/calc_statevector_dim.html"},{"title":"fill2d_ensarray – NEMO4 PDAFOMI","text":"public subroutine fill2d_ensarray(fname, ens_p) Uses netcdf Fill local ensemble array with 2d state variables from\n initial state file. Arguments Type Intent Optional Attributes Name character(len=lc), intent(in) :: fname Name of netCDF file real(kind=pwp), intent(inout) :: ens_p (:,:) PE-local state ensemble Contents Source Code fill2d_ensarray Source Code SUBROUTINE fill2d_ensarray ( fname , ens_p ) USE netcdf !> Name of netCDF file CHARACTER ( lc ), INTENT ( in ) :: fname !> PE-local state ensemble REAL ( pwp ), INTENT ( inout ) :: ens_p (:, :) WRITE ( * , '(/1x,a,a)' ) '2D initial state file =' , TRIM ( fname ) WRITE ( * , '(/1x,a)' ) 'Insert routine for reading 2D initial state here.' END SUBROUTINE fill2d_ensarray","tags":"","loc":"proc/fill2d_ensarray.html"},{"title":"fill3d_ensarray – NEMO4 PDAFOMI","text":"public subroutine fill3d_ensarray(fname, statevar, ens_p) Uses netcdf Fill local ensemble array with 3d state variables from\n initial state file. Arguments Type Intent Optional Attributes Name character(len=lc), intent(in) :: fname Name of netCDF file character(len=1), intent(in) :: statevar Name of state variable real(kind=pwp), intent(inout) :: ens_p (:,:) PE-local state ensemble Contents Source Code fill3d_ensarray Source Code SUBROUTINE fill3d_ensarray ( fname , statevar , ens_p ) USE netcdf !> Name of netCDF file CHARACTER ( lc ), INTENT ( in ) :: fname !> Name of state variable CHARACTER ( len = 1 ), INTENT ( in ) :: statevar !> PE-local state ensemble REAL ( pwp ), INTENT ( inout ) :: ens_p (:, :) SELECT CASE ( statevar ) CASE ( 'T' ) WRITE ( * , '(/1x,a,a)' ) 'T initial state file =' , TRIM ( fname ) WRITE ( * , '(/1x,a)' ) 'Insert routine for reading T initial state here.' CASE ( 'S' ) WRITE ( * , '(/1x,a,a)' ) 'S initial state file =' , TRIM ( fname ) WRITE ( * , '(/1x,a)' ) 'Insert routine for reading S initial state here.' CASE ( 'U' ) WRITE ( * , '(/1x,a,a)' ) 'U initial state file =' , TRIM ( fname ) WRITE ( * , '(/1x,a)' ) 'Insert routine for reading U initial state here.' CASE ( 'V' ) WRITE ( * , '(/1x,a,a)' ) 'V initial state file =' , TRIM ( fname ) WRITE ( * , '(/1x,a)' ) 'Insert routine for reading V initial state here.' END SELECT END SUBROUTINE fill3d_ensarray","tags":"","loc":"proc/fill3d_ensarray.html"},{"title":"init_info_pdaf – NEMO4 PDAFOMI","text":"public subroutine init_info_pdaf() Uses mod_assimilation_pdaf This routine performs a model-sided screen output about\n the coniguration of the data assimilation system. Calling Sequence Called from: init_pdaf Arguments None Contents Source Code init_info_pdaf Source Code SUBROUTINE init_info_pdaf () USE mod_assimilation_pdaf , & ! Variables for assimilation ONLY : filtertype , subtype , dim_ens , delt_obs , model_error , & model_err_amp , forget , rank_analysis_enkf , int_rediag ! ***************************** ! *** Initial Screen output *** ! ***************************** IF ( filtertype == 0 ) THEN WRITE ( * , '(/21x, a)' ) 'Filter: SEEK' IF ( subtype == 2 ) THEN WRITE ( * , '(6x, a)' ) '-- fixed basis filter with update of matrix U' WRITE ( * , '(6x, a)' ) '-- no re-diagonalization of VUV&#94;T' ELSE IF ( subtype == 3 ) THEN WRITE ( * , '(6x, a)' ) '-- fixed basis filter & no update of matrix U' WRITE ( * , '(6x, a)' ) '-- no re-diagonalization of VUV&#94;T' ELSE IF ( subtype == 5 ) THEN WRITE ( * , '(6x, a)' ) '-- Offline mode' END IF WRITE ( * , '(13x, a, i5)' ) 'number of EOFs:' , dim_ens IF ( subtype /= 5 ) WRITE ( * , '(6x, a, i5)' ) 'Assimilation interval:' , delt_obs WRITE ( * , '(10x, a, f5.2)' ) 'forgetting factor:' , forget IF ( subtype /= 5 ) THEN IF (( int_rediag > 0 ) . AND . (( subtype /= 2 ) . OR . ( subtype /= 3 ))) & WRITE ( * , '(10x, a, i4, a)' ) & 'Re-diag each ' , int_rediag , '-th analysis step' ELSE IF ( int_rediag == 1 ) THEN WRITE ( * , '(10x, a)' ) 'Perform re-diagonalization' ELSE WRITE ( * , '(10x, a)' ) 'No re-diagonalization' END IF END IF ELSE IF ( filtertype == 1 ) THEN WRITE ( * , '(21x, a)' ) 'Filter: SEIK' IF ( subtype == 2 ) THEN WRITE ( * , '(6x, a)' ) '-- fixed error-space basis' ELSE IF ( subtype == 3 ) THEN WRITE ( * , '(6x, a)' ) '-- fixed state covariance matrix' ELSE IF ( subtype == 4 ) THEN WRITE ( * , '(6x, a)' ) '-- use ensemble transformation' ELSE IF ( subtype == 5 ) THEN WRITE ( * , '(6x, a)' ) '-- Offline mode' END IF WRITE ( * , '(14x, a, i5)' ) 'ensemble size:' , dim_ens IF ( subtype /= 5 ) WRITE ( * , '(6x, a, i5)' ) 'Assimilation interval:' , delt_obs WRITE ( * , '(10x, a, f5.2)' ) 'forgetting factor:' , forget IF ( model_error ) THEN WRITE ( * , '(6x, a, f5.2)' ) 'model error amplitude:' , model_err_amp END IF ELSE IF ( filtertype == 2 ) THEN WRITE ( * , '(21x, a)' ) 'Filter: EnKF' IF ( subtype == 5 ) THEN WRITE ( * , '(6x, a)' ) '-- Offline mode' END IF WRITE ( * , '(14x, a, i5)' ) 'ensemble size:' , dim_ens IF ( subtype /= 5 ) WRITE ( * , '(6x, a, i5)' ) 'Assimilation interval:' , delt_obs WRITE ( * , '(10x, a, f5.2)' ) 'forgetting factor:' , forget IF ( model_error ) THEN WRITE ( * , '(6x, a, f5.2)' ) 'model error amplitude:' , model_err_amp END IF IF ( rank_analysis_enkf > 0 ) THEN WRITE ( * , '(6x, a, i5)' ) & 'analysis with pseudo-inverse of HPH, rank:' , rank_analysis_enkf END IF ELSE IF ( filtertype == 3 ) THEN WRITE ( * , '(21x, a)' ) 'Filter: LSEIK' IF ( subtype == 2 ) THEN WRITE ( * , '(6x, a)' ) '-- fixed error-space basis' ELSE IF ( subtype == 3 ) THEN WRITE ( * , '(6x, a)' ) '-- fixed state covariance matrix' ELSE IF ( subtype == 4 ) THEN WRITE ( * , '(6x, a)' ) '-- use ensemble transformation' ELSE IF ( subtype == 5 ) THEN WRITE ( * , '(6x, a)' ) '-- Offline mode' END IF WRITE ( * , '(14x, a, i5)' ) 'ensemble size:' , dim_ens IF ( subtype /= 5 ) WRITE ( * , '(6x, a, i5)' ) 'Assimilation interval:' , delt_obs WRITE ( * , '(10x, a, f5.2)' ) 'forgetting factor:' , forget IF ( model_error ) THEN WRITE ( * , '(6x, a, f5.2)' ) 'model error amplitude:' , model_err_amp END IF ELSE IF ( filtertype == 4 ) THEN WRITE ( * , '(21x, a)' ) 'Filter: ETKF' IF ( subtype == 0 ) THEN WRITE ( * , '(6x, a)' ) '-- Variant using T-matrix' ELSE IF ( subtype == 1 ) THEN WRITE ( * , '(6x, a)' ) '-- Variant following Hunt et al. (2007)' ELSE IF ( subtype == 5 ) THEN WRITE ( * , '(6x, a)' ) '-- Offline mode' END IF WRITE ( * , '(14x, a, i5)' ) 'ensemble size:' , dim_ens IF ( subtype /= 5 ) WRITE ( * , '(6x, a, i5)' ) 'Assimilation interval:' , delt_obs WRITE ( * , '(10x, a, f5.2)' ) 'forgetting factor:' , forget IF ( model_error ) THEN WRITE ( * , '(6x, a, f5.2)' ) 'model error amplitude:' , model_err_amp END IF ELSE IF ( filtertype == 5 ) THEN WRITE ( * , '(21x, a)' ) 'Filter: LETKF' IF ( subtype == 0 ) THEN WRITE ( * , '(6x, a)' ) '-- Variant using T-matrix' ELSE IF ( subtype == 1 ) THEN WRITE ( * , '(6x, a)' ) '-- Variant following Hunt et al. (2007)' ELSE IF ( subtype == 5 ) THEN WRITE ( * , '(6x, a)' ) '-- Offline mode' END IF WRITE ( * , '(14x, a, i5)' ) 'ensemble size:' , dim_ens IF ( subtype /= 5 ) WRITE ( * , '(6x, a, i5)' ) 'Assimilation interval:' , delt_obs WRITE ( * , '(10x, a, f5.2)' ) 'forgetting factor:' , forget IF ( model_error ) THEN WRITE ( * , '(6x, a, f5.2)' ) 'model error amplitude:' , model_err_amp END IF ELSE IF ( filtertype == 6 ) THEN WRITE ( * , '(21x, a)' ) 'Filter: ESTKF' IF ( subtype == 0 ) THEN WRITE ( * , '(6x, a)' ) '-- Standard mode' ELSE IF ( subtype == 5 ) THEN WRITE ( * , '(6x, a)' ) '-- Offline mode' END IF WRITE ( * , '(14x, a, i5)' ) 'ensemble size:' , dim_ens IF ( subtype /= 5 ) WRITE ( * , '(6x, a, i5)' ) 'Assimilation interval:' , delt_obs WRITE ( * , '(10x, a, f5.2)' ) 'forgetting factor:' , forget IF ( model_error ) THEN WRITE ( * , '(6x, a, f5.2)' ) 'model error amplitude:' , model_err_amp END IF ELSE IF ( filtertype == 7 ) THEN WRITE ( * , '(21x, a)' ) 'Filter: LESTKF' IF ( subtype == 0 ) THEN WRITE ( * , '(6x, a)' ) '-- Standard mode' ELSE IF ( subtype == 5 ) THEN WRITE ( * , '(6x, a)' ) '-- Offline mode' END IF WRITE ( * , '(14x, a, i5)' ) 'ensemble size:' , dim_ens IF ( subtype /= 5 ) WRITE ( * , '(6x, a, i5)' ) 'Assimilation interval:' , delt_obs WRITE ( * , '(10x, a, f5.2)' ) 'forgetting factor:' , forget IF ( model_error ) THEN WRITE ( * , '(6x, a, f5.2)' ) 'model error amplitude:' , model_err_amp END IF END IF END SUBROUTINE init_info_pdaf","tags":"","loc":"proc/init_info_pdaf.html"},{"title":"read_config_pdaf – NEMO4 PDAFOMI","text":"public subroutine read_config_pdaf() Uses mod_parallel_pdaf mod_assimilation_pdaf This routine reads the namelist file with parameters\n controlling data assimilation with PDAF and outputs to\n screen. Calling Sequence Called from: init_pdaf Arguments None Contents Variables nmlfile Source Code read_config_pdaf Variables Type Visibility Attributes Name Initial character(len=lc), public :: nmlfile Namelist file Source Code SUBROUTINE read_config_pdaf () USE mod_parallel_pdaf , & ONLY : mype_ens USE mod_assimilation_pdaf , & ONLY : filtertype , subtype , dim_ens , delt_obs , & screen , forget , local_range , locweight , srange , istate_t , & istate_s , istate_u , istate_v , istate_ssh !> Namelist file CHARACTER ( lc ) :: nmlfile NAMELIST / pdaf_nml / filtertype , subtype , dim_ens , & delt_obs , screen , forget , local_range , locweight , & srange , istate_s , istate_t , istate_u , istate_v , istate_ssh ! **************************************************** ! ***   Initialize PDAF parameters from namelist   *** ! **************************************************** nmlfile = 'namelist.pdaf' OPEN ( 20 , file = nmlfile ) READ ( 20 , NML = pdaf_nml ) CLOSE ( 20 ) ! Print PDAF parameters to screen showconf : IF ( mype_ens == 0 ) THEN WRITE ( * , '(/1x,a)' ) '-- Overview of PDAF configuration --' WRITE ( * , '(3x,a)' ) 'PDAF [pdaf_nml]:' WRITE ( * , '(5x,a,i10)' ) 'filtertype   ' , filtertype WRITE ( * , '(5x,a,i10)' ) 'subtype      ' , subtype WRITE ( * , '(5x,a,i10)' ) 'dim_ens      ' , dim_ens WRITE ( * , '(5x,a,i10)' ) 'delt_obs     ' , delt_obs WRITE ( * , '(5x,a,i10)' ) 'screen       ' , screen WRITE ( * , '(5x,a,f10.2)' ) 'forget       ' , forget WRITE ( * , '(5x,a,es10.2)' ) 'local_range  ' , local_range WRITE ( * , '(5x,a,i10)' ) 'locweight    ' , locweight WRITE ( * , '(5x,a,es10.2)' ) 'srange       ' , srange WRITE ( * , '(5x,a,a)' ) 'istate_t   ' , istate_t WRITE ( * , '(5x,a,a)' ) 'istate_s   ' , istate_s WRITE ( * , '(5x,a,a)' ) 'istate_u   ' , istate_u WRITE ( * , '(5x,a,a)' ) 'istate_v   ' , istate_v WRITE ( * , '(5x,a,a)' ) 'istate_ssh ' , istate_ssh WRITE ( * , '(1x,a)' ) '-- End of PDAF configuration overview --' END IF showconf END SUBROUTINE read_config_pdaf","tags":"","loc":"proc/read_config_pdaf.html"},{"title":"mod_init_pdaf – NEMO4 PDAFOMI","text":"Initialise PDAF This modules contains the initialisation routine for PDAF init_pdaf . Here the ensemble is initialised and distributed\nand the statevector and state variable information is computed. Uses mod_kind_pdaf Contents Subroutines init_pdaf Subroutines public subroutine init_pdaf () This routine collects the initialization of variables for PDAF.\n In addition, the initialization routine PDAF_init is called\n such that the internal initialization of PDAF is performed.\n This variant is for the online mode of PDAF. Read more… Arguments None","tags":"","loc":"module/mod_init_pdaf.html"},{"title":"mod_parallel_pdaf – NEMO4 PDAFOMI","text":"Setup parallelisation This modules provides variables for the MPI parallelization\nto be shared between model-related routines. There are variables\nthat are used in the model even without PDAF, and additional variables\nthat are only used if data assimilaion with PDAF is performed.\nThe initialization of communicators for execution with PDAF is\nperformed in init_parallel_pdaf . Uses mod_kind_pdaf Contents Variables COMM_couple COMM_ensemble COMM_filter COMM_model MPIerr MPIstatus filterpe local_npes_model mype_couple mype_ens mype_filter mype_model n_modeltasks npes_couple npes_ens npes_filter npes_model screen_parallel task_id Subroutines abort_parallel init_parallel_pdaf Variables Type Visibility Attributes Name Initial integer, public :: COMM_couple MPI communicator for coupling filter and model integer, public :: COMM_ensemble Communicator for entire ensemble integer, public :: COMM_filter MPI communicator for filter PEs integer, public :: COMM_model MPI communicator for model tasks integer, public :: MPIerr Error flag for MPI integer, public :: MPIstatus (MPI_STATUS_SIZE) Status array for MPI logical, public :: filterpe Whether we are on a PE in a COMM_filter integer, public, ALLOCATABLE :: local_npes_model (:) # PEs per ensemble integer, public :: mype_couple rank and size in COMM_couple integer, public :: mype_ens Rank and size in COMM_ensemble integer, public :: mype_filter rank and size in COMM_filter integer, public :: mype_model Rank and size in COMM_model integer, public :: n_modeltasks = 1 Number of parallel model tasks integer, public :: npes_couple rank and size in COMM_couple integer, public :: npes_ens Rank and size in COMM_ensemble integer, public :: npes_filter rank and size in COMM_filter integer, public :: npes_model Rank and size in COMM_model integer, public :: screen_parallel = 1 Option for screen output integer, public :: task_id Index of my model task (1,…,n_modeltasks) Subroutines public subroutine abort_parallel () Terminate the MPI execution environment. Arguments None public subroutine init_parallel_pdaf (screen, mpi_comm) Split the MPI communicator initialised by XIOS into MODEL,\n FILTER and COUPLE communicators, return MODEL communicator. Read more… Arguments Type Intent Optional Attributes Name integer, intent(in) :: screen Whether screen information is shown integer, intent(inout) :: mpi_comm Communicator after XIOS splitting","tags":"","loc":"module/mod_parallel_pdaf.html"},{"title":"mod_statevector_pdaf – NEMO4 PDAFOMI","text":"Building the Statevector This module provides variables & routines for\nbuilding the state vector. Uses mod_kind_pdaf Contents Variables mpi_subd_lat mpi_subd_lon mpi_subd_vert s_p_dim s_p_offset ssh_p_dim ssh_p_offset t_p_dim t_p_offset u_p_dim u_p_offset v_p_dim v_p_offset Subroutines calc_mpi_dim calc_offset calc_statevar_dim calc_statevector_dim fill2d_ensarray fill3d_ensarray Variables Type Visibility Attributes Name Initial integer, public :: mpi_subd_lat Dimensions for MPI subdomain that is included\n in local statevector. Necessary so that halo\n regions are not included in multiple local\n statevectors integer, public :: mpi_subd_lon integer, public :: mpi_subd_vert integer, public :: s_p_dim integer, public :: s_p_offset integer, public :: ssh_p_dim 2d statevector variables - dimension size integer, public :: ssh_p_offset 2d statevector variables - start index integer, public :: t_p_dim 3d statevector variables - dimension size integer, public :: t_p_offset 3d statevector variables - start index integer, public :: u_p_dim integer, public :: u_p_offset integer, public :: v_p_dim integer, public :: v_p_offset Subroutines public subroutine calc_mpi_dim () This routine calculates the dimensions of the MPI subdomain\n that is used to fill the local statevector. Arguments None public subroutine calc_offset () This routine calculates the offset values for each of the\n local statevector variables. It then stores the 2d/3d offset\n values in separate arrays. Arguments None public subroutine calc_statevar_dim () This routine calculates the dimension of each of the local\n statevector variables. Arguments None public subroutine calc_statevector_dim (dim_p) This routine calculates the dimension of the local statevector. Arguments Type Intent Optional Attributes Name integer, intent(inout) :: dim_p Local statevector dimension public subroutine fill2d_ensarray (fname, ens_p) Fill local ensemble array with 2d state variables from\n initial state file. Arguments Type Intent Optional Attributes Name character(len=lc), intent(in) :: fname Name of netCDF file real(kind=pwp), intent(inout) :: ens_p (:,:) PE-local state ensemble public subroutine fill3d_ensarray (fname, statevar, ens_p) Fill local ensemble array with 3d state variables from\n initial state file. Arguments Type Intent Optional Attributes Name character(len=lc), intent(in) :: fname Name of netCDF file character(len=1), intent(in) :: statevar Name of state variable real(kind=pwp), intent(inout) :: ens_p (:,:) PE-local state ensemble","tags":"","loc":"module/mod_statevector_pdaf.html"},{"title":"mod_util_pdaf – NEMO4 PDAFOMI","text":"Utility Routines This module contains several routines useful for common\nmodel tasks. The initial routines included output configuration\ninformation about the PDAF library, and configuration information\nabout the assimilation parameters. Uses mod_kind_pdaf Contents Subroutines init_info_pdaf read_config_pdaf Subroutines public subroutine init_info_pdaf () This routine performs a model-sided screen output about\n the coniguration of the data assimilation system. Read more… Arguments None public subroutine read_config_pdaf () This routine reads the namelist file with parameters\n controlling data assimilation with PDAF and outputs to\n screen. Read more… Arguments None","tags":"","loc":"module/mod_util_pdaf.html"},{"title":"mod_kind_pdaf – NEMO4 PDAFOMI","text":"Define real precision This module defines the kind of real and length of character strings\nfor the PDAF call-back routines and interfaces. It is based on the NEMO\nmodule par_kind.F90 . Contents Variables lc pdp pwp Variables Type Visibility Attributes Name Initial integer, public, parameter :: lc = 256 integer, public, parameter :: pdp = SELECTED_REAL_KIND(12, 307) integer, public, parameter :: pwp = pdp","tags":"","loc":"module/mod_kind_pdaf.html"},{"title":"mod_assimilation_pdaf – NEMO4 PDAFOMI","text":"Assimilation Parameters This module provides variables needed for the\nassimilation. See mod_init_pdaf for where many of these\nvariables are initialised. Uses mod_kind_pdaf Contents Variables coords_l coords_obs_f covartype delt_obs dim_bias dim_ens dim_lag dim_obs dim_obs_p dim_state dim_state_p distance_l epsilon filtertype forget incremental indx_dom_l int_rediag istate_s istate_ssh istate_t istate_u istate_v local_range locweight model_err_amp model_error obs_f obs_index_l obs_index_p obs_p rank_analysis_enkf screen srange subtype time type_forget type_sqrt type_trans Variables Type Visibility Attributes Name Initial real(kind=pwp), public :: coords_l (2) Coordinates of local analysis domain real(kind=pwp), public, ALLOCATABLE :: coords_obs_f (:,:) Array for full observation coordinates integer, public :: covartype For SEIK: Definition of ensemble covar matrix\n (0): Factor (r+1)&#94;-1 (or N&#94;-1)\n (1): Factor r&#94;-1 (or (N-1)&#94;-1) - real ensemble covar.\n This setting is only for the model part; The definition\n of P has also to be specified in PDAF_filter_init.\n Only for upward-compatibility of PDAF integer, public :: delt_obs time step interval between assimilation steps integer, public :: dim_bias dimension of bias vector integer, public :: dim_ens Size of ensemble for SEIK/LSEIK/EnKF/ETKF\n Number of EOFs to be used for SEEK integer, public :: dim_lag Number of time instances for smoother integer, public :: dim_obs Number of observations integer, public :: dim_obs_p Process-local number of observations integer, public :: dim_state Global model state dimension integer, public :: dim_state_p Model state dimension for PE-local domain real(kind=pwp), public, ALLOCATABLE :: distance_l (:) Vector holding distances of local observations real(kind=pwp), public :: epsilon Epsilon for gradient approx. in SEEK forecast integer, public :: filtertype Select filter algorithm:\n SEEK (0), SEIK (1), EnKF (2), LSEIK (3), ETKF (4)\n LETKF (5), ESTKF (6), LESTKF (7), NETF (9), LNETF (10) real(kind=pwp), public :: forget Forgetting factor for filter analysis integer, public :: incremental Perform incremental updating in LSEIK real(kind=pwp), public, ALLOCATABLE :: indx_dom_l (:,:) Indices of local analysis domain integer, public :: int_rediag Interval to perform re-diagonalization in SEEK character(len=lc), public :: istate_s file for t initial state estimate character(len=lc), public :: istate_ssh file for ssh initial state estimate character(len=lc), public :: istate_t file for t initial state estimate character(len=lc), public :: istate_u file for u initial state estimate character(len=lc), public :: istate_v file for v initial state estimate real(kind=pwp), public :: local_range Range for local observation domain - NEMO grid integer, public :: locweight Type of localizing weighting of observations\n   (0) constant weight of 1\n   (1) exponentially decreasing with SRANGE\n   (2) use 5th-order polynomial\n   (3) regulated localization of R with mean error variance\n   (4) regulated localization of R with single-point error variance real(kind=pwp), public :: model_err_amp Amplitude for model error logical, public :: model_error Control application of model error real(kind=pwp), public, ALLOCATABLE :: obs_f (:) Vector holding full vector of observations integer, public, ALLOCATABLE :: obs_index_l (:) Vector holding local state-vector indices of observations integer, public, ALLOCATABLE :: obs_index_p (:) Vector holding state-vector indices of observations real(kind=pwp), public, ALLOCATABLE :: obs_p (:) Vector holding process-local observations integer, public :: rank_analysis_enkf Rank to be considered for inversion of HPH integer, public :: screen Control verbosity of PDAF\n (0) no outputs, (1) progess info, (2) add timings\n (3) debugging output real(kind=pwp), public :: srange Support range for 5th order polynomial - NEMO grid\n   or radius for 1/e for exponential weighting\n    ! SEIK-subtype4/LSEIK-subtype4/ESTKF/LESTKF integer, public :: subtype Subtype of filter algorithm\n   SEEK:\n     (0) evolve normalized modes\n     (1) evolve scaled modes with unit U\n     (2) fixed basis (V); variable U matrix\n     (3) fixed covar matrix (V,U kept static)\n   SEIK:\n     (0) ensemble forecast; new formulation\n     (1) ensemble forecast; old formulation\n     (2) fixed error space basis\n     (3) fixed state covariance matrix\n     (4) SEIK with ensemble transformation\n   EnKF:\n     (0) analysis for large observation dimension\n     (1) analysis for small observation dimension\n   LSEIK:\n     (0) ensemble forecast;\n     (2) fixed error space basis\n     (3) fixed state covariance matrix\n     (4) LSEIK with ensemble transformation\n   ETKF:\n     (0) ETKF using T-matrix like SEIK\n     (1) ETKF following Hunt et al. (2007)\n       There are no fixed basis/covariance cases, as\n       these are equivalent to SEIK subtypes 2/3\n   LETKF:\n     (0) LETKF using T-matrix like SEIK\n     (1) LETKF following Hunt et al. (2007)\n       There are no fixed basis/covariance cases, as\n       these are equivalent to LSEIK subtypes 2/3\n   ESTKF:\n     (0) standard ESTKF\n       There are no fixed basis/covariance cases, as\n       these are equivalent to SEIK subtypes 2/3\n   LESTKF:\n     (0) standard LESTKF\n       There are no fixed basis/covariance cases, as\n       these are equivalent to LSEIK subtypes 2/3\n   NETF:\n     (0) standard NETF\n   LNETF:\n     (0) standard LNETF real(kind=pwp), public :: time model time integer, public :: type_forget Type of forgetting factor integer, public :: type_sqrt Type of the transform matrix square-root\n (0) symmetric square root, (1) Cholesky decomposition integer, public :: type_trans Type of ensemble transformation\n SEIK/LSEIK:\n (0) use deterministic omega\n (1) use random orthonormal omega orthogonal to (1,…,1)&#94;T\n (2) use product of (0) with random orthonormal matrix with\n     eigenvector (1,…,1)&#94;T\n ETKF/LETKF with subtype=4:\n (0) use deterministic symmetric transformation\n (2) use product of (0) with random orthonormal matrix with\n     eigenvector (1,…,1)&#94;T\n ESTKF/LESTKF:\n (0) use deterministic omega\n (1) use random orthonormal omega orthogonal to (1,…,1)&#94;T\n (2) use product of (0) with random orthonormal matrix with\n     eigenvector (1,…,1)&#94;T\n NETF/LNETF:\n (0) use random orthonormal transformation orthogonal to (1,…,1)&#94;T\n (1) use identity transformation\n    ! LSEIK/LETKF/LESTKF","tags":"","loc":"module/mod_assimilation_pdaf.html"}]}